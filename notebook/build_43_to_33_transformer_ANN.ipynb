{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['附件二.xlsx',\n",
       " '200mb201909.csv',\n",
       " 'FCFC Import Naphtha Composition Lab_001~100_R2.xlsx',\n",
       " 'Aroma-1 Unit 000 Split_Factor Calculation.xlsx',\n",
       " '200mb201701r2.csv',\n",
       " '附件一.xlsx']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings;warnings.simplefilter('ignore')\n",
    "import os\n",
    "import torch\n",
    "import torchviz\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torch import tensor\n",
    "from torch.nn import Linear,ReLU,Sigmoid,Tanh,Dropout\n",
    "import torch.optim as optim\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "root = '../data/phase_2/raw/other/'\n",
    "os.listdir(root)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "讀檔案 : (829, 108)\n",
      "Shape Of The Before Ouliers:  (829, 110)\n",
      "Shape Of The After Ouliers:  (576, 110)\n",
      "Shape Of The Before Ouliers:  (27, 110)\n",
      "Shape Of The After Ouliers:  (20, 110)\n"
     ]
    }
   ],
   "source": [
    "data = pd.read_csv(root+\"200mb201701r2.csv\", encoding = 'big5', header = 0)\n",
    "print('讀檔案 : ' + str(data.shape))\n",
    "testdata = pd.read_csv(root+\"200mb201909.csv\", encoding = 'big5', header = 0)\n",
    "# steam = dcs['ARO1-DCS-FIC55301'] + dcs['ARO1-DCS-FIC55501'] + dcs['ARO1-DCS-FIC55601']\n",
    "# dcs['steam'] = steam\n",
    "C9A = data['Feed    C9 Aromtics'] + data['Feed    C10+ Aromtics']\n",
    "AROMA = data['Product    C9 Aromtics'] + data['Product    C10+ Aromtics']+ data['Product    Benzene']+ data['Product    Toluene']+ data['Product    Ethylbenzene']+ data['Product    P-Xylene']+ data['Product    M-Xylene']+ data['Product    O-Xylene']\n",
    "data['C9A'] = C9A\n",
    "data['AROMA'] = AROMA\n",
    "C9A = testdata['Feed    C9 Aromtics'] + testdata['Feed    C10+ Aromtics']\n",
    "AROMA = testdata['Product    C9 Aromtics'] + testdata['Product    C10+ Aromtics']+ testdata['Product    Benzene']+ testdata['Product    Toluene']+ testdata['Product    Ethylbenzene']+ testdata['Product    P-Xylene']+ testdata['Product    M-Xylene']+ testdata['Product    O-Xylene']\n",
    "testdata['C9A'] = C9A\n",
    "testdata['AROMA'] = AROMA\n",
    "\n",
    "print (\"Shape Of The Before Ouliers: \",data.shape)\n",
    "data = data[(data[\"Naphtha Feed Rate, m3/hr\"]<=100 )&(data[\"Naphtha Feed Rate, m3/hr\"] >= 99)]\n",
    "print (\"Shape Of The After Ouliers: \",data.shape)\n",
    "print (\"Shape Of The Before Ouliers: \",testdata.shape)\n",
    "testdata = testdata[(testdata[\"Naphtha Feed Rate, m3/hr\"]<=100 )&(testdata[\"Naphtha Feed Rate, m3/hr\"] >= 99)]\n",
    "print (\"Shape Of The After Ouliers: \",testdata.shape)\n",
    "testdata.index = range(len(testdata))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# x_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_col  = [\n",
    "\"    N+2A in Naphtha Feed, wt%\", #\"ARO1-LIMS-s201-Naphthenes-ALL\" + 2*\"ARO1-LIMS-s201-Aromatics-ALL\"\n",
    "\"    Chlorine in Fresh Catalyst, wt%\", #\"ARO1-LIMS-S307-CL\"\n",
    "\"Carbon in Spent Catalyst, %\",  #\"ARO1-LIMS-S301-CARBON\"  \n",
    "\"    C6P- in Naphtha Feed, wt%\",  #\"ARO1-LIMS-s201-Paraffins-6\"  \n",
    "\"    3R211 Inlet Tem, oC\",  #\"ARO1-DCS-TIC20102 Setpoint\"\n",
    "\"    3R212 Inlet Temp, oC\", #\"ARO1-DCS-TIC20202 Setpoint\"\n",
    "\"    3R213 Inlet Temp, oC\", #\"ARO1-DCS-TIC20302 Setpoint\"\n",
    "\"    3R214 Inlet Temp, oC\", #\"ARO1-DCS-TIC20402 Setpoint\"\n",
    "\"Feed    Hydrogen\",\n",
    "\"Feed    Methane\",\n",
    "\"Feed    Ethane\",\n",
    "\"Feed    Propane\",\n",
    "\"Feed    n-Butane\",\n",
    "\"Feed    i-Butane\",\n",
    "\"Feed    C4 Naphthenes\",\n",
    "\"Feed    n-Pentane\",\n",
    "\"Feed    C5 i-Paraffins\",\n",
    "\"Feed    C5 Naphthenes\",\n",
    "\"Feed    n-Hexane\",\n",
    "\"Feed    C6 i-Paraffins\",\n",
    "\"Feed    C6 Naphthenes\",\n",
    "\"Feed    Benzene\",\n",
    "\"Feed    n-Heptane\",\n",
    "\"Feed    C7 i-Paraffins\",\n",
    "\"Feed    C7 Naphthenes\",\n",
    "\"Feed    Toluene\",\n",
    "\"Feed    n-Octane\",\n",
    "\"Feed    C8 i-Paraffins\",\n",
    "\"Feed    C8 Naphthenes\",\n",
    "\"Feed    Ethylbenzene\",\n",
    "\"Feed    P-Xylene\",\n",
    "\"Feed    M-Xylene\",\n",
    "\"Feed    O-Xylene\",\n",
    "\"Feed    n-Nonane\",\n",
    "\"Feed    C9 i-Paraffins\",\n",
    "\"Feed    C9 Naphthenes\",\n",
    "\"Feed    C9 Aromtics\",\n",
    "\"Feed    C10+ n-Paraffins\",\n",
    "\"Feed    C10+ i-Paraffins\",\n",
    "\"Feed    C10+ Naphthenes\",\n",
    "\"Feed    C10+ Aromtics\",\n",
    "\"Product Separator Pressure, kg/cm2_g\", #\"ARO1-DCS-PIC21501 Setpoint\"\n",
    "# \"Product Separator Temp, oC\",\n",
    "\"H2/HC Ratio\"                           #\"ARO1-DCS-R211_HC\"\n",
    "         \n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['    N+2A in Naphtha Feed, wt%',\n",
       " '    Chlorine in Fresh Catalyst, wt%',\n",
       " 'Carbon in Spent Catalyst, %',\n",
       " '    C6P- in Naphtha Feed, wt%',\n",
       " '    3R211 Inlet Tem, oC',\n",
       " '    3R212 Inlet Temp, oC',\n",
       " '    3R213 Inlet Temp, oC',\n",
       " '    3R214 Inlet Temp, oC',\n",
       " 'Feed    Hydrogen',\n",
       " 'Feed    Methane',\n",
       " 'Feed    Ethane',\n",
       " 'Feed    Propane',\n",
       " 'Feed    n-Butane',\n",
       " 'Feed    i-Butane',\n",
       " 'Feed    C4 Naphthenes',\n",
       " 'Feed    n-Pentane',\n",
       " 'Feed    C5 i-Paraffins',\n",
       " 'Feed    C5 Naphthenes',\n",
       " 'Feed    n-Hexane',\n",
       " 'Feed    C6 i-Paraffins',\n",
       " 'Feed    C6 Naphthenes',\n",
       " 'Feed    Benzene',\n",
       " 'Feed    n-Heptane',\n",
       " 'Feed    C7 i-Paraffins',\n",
       " 'Feed    C7 Naphthenes',\n",
       " 'Feed    Toluene',\n",
       " 'Feed    n-Octane',\n",
       " 'Feed    C8 i-Paraffins',\n",
       " 'Feed    C8 Naphthenes',\n",
       " 'Feed    Ethylbenzene',\n",
       " 'Feed    P-Xylene',\n",
       " 'Feed    M-Xylene',\n",
       " 'Feed    O-Xylene',\n",
       " 'Feed    n-Nonane',\n",
       " 'Feed    C9 i-Paraffins',\n",
       " 'Feed    C9 Naphthenes',\n",
       " 'Feed    C9 Aromtics',\n",
       " 'Feed    C10+ n-Paraffins',\n",
       " 'Feed    C10+ i-Paraffins',\n",
       " 'Feed    C10+ Naphthenes',\n",
       " 'Feed    C10+ Aromtics',\n",
       " 'Product Separator Pressure, kg/cm2_g',\n",
       " 'H2/HC Ratio']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# y_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "script = '''\n",
    "y1 = data[\"Product    Hydrogen\"]\n",
    "y2 = data[\"Product    Methane\"]\n",
    "y3 = data[\"Product    Ethane\"]\n",
    "y4 = data[\"Product    Propane\"]\n",
    "y5 = data[\"Product    n-Butane\"]\n",
    "y6 = data[\"Product    i-Butane\"]\n",
    "y7 = data[\"Product    C4 Naphthenes\"]\n",
    "y8 = data[\"Product    n-Pentane\"]\n",
    "y9 = data[\"Product    C5 i-Paraffins\"]\n",
    "y10 = data[\"Product    C5 Naphthenes\"]\n",
    "y11 = data[\"Product    n-Hexane\"]\n",
    "y12 = data[\"Product    C6 i-Paraffins\"]\n",
    "y13 = data[\"Product    C6 Naphthenes\"]\n",
    "y14 = data[\"Product    Benzene\"]\n",
    "y15 = data[\"Product    n-Heptane\"]\n",
    "y16 = data[\"Product    C7 i-Paraffins\"]\n",
    "y17 = data[\"Product    C7 Naphthenes\"]\n",
    "y18 = data[\"Product    Toluene\"]\n",
    "y19 = data[\"Product    n-Octane\"]\n",
    "y20 = data[\"Product    C8 i-Paraffins\"]\n",
    "y21 = data[\"Product    C8 Naphthenes\"]\n",
    "y22 = data[\"Product    Ethylbenzene\"]\n",
    "y23 = data[\"Product    P-Xylene\"]\n",
    "y24 = data[\"Product    M-Xylene\"]\n",
    "y25 = data[\"Product    O-Xylene\"]\n",
    "y26 = data[\"Product    n-Nonane\"]\n",
    "y27 = data[\"Product    C9 i-Paraffins\"]\n",
    "y28 = data[\"Product    C9 Naphthenes\"]\n",
    "y29 = data[\"Product    C9 Aromtics\"]\n",
    "y30 = data[\"Product    C10+ n-Paraffins\"]\n",
    "y31 = data[\"Product    C10+ i-Paraffins\"]\n",
    "y32 = data[\"Product    C10+ Naphthenes\"]\n",
    "y33 = data[\"Product    C10+ Aromtics\"]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Product    Hydrogen',\n",
       " 'Product    Methane',\n",
       " 'Product    Ethane',\n",
       " 'Product    Propane',\n",
       " 'Product    n-Butane',\n",
       " 'Product    i-Butane',\n",
       " 'Product    C4 Naphthenes',\n",
       " 'Product    n-Pentane',\n",
       " 'Product    C5 i-Paraffins',\n",
       " 'Product    C5 Naphthenes',\n",
       " 'Product    n-Hexane',\n",
       " 'Product    C6 i-Paraffins',\n",
       " 'Product    C6 Naphthenes',\n",
       " 'Product    Benzene',\n",
       " 'Product    n-Heptane',\n",
       " 'Product    C7 i-Paraffins',\n",
       " 'Product    C7 Naphthenes',\n",
       " 'Product    Toluene',\n",
       " 'Product    n-Octane',\n",
       " 'Product    C8 i-Paraffins',\n",
       " 'Product    C8 Naphthenes',\n",
       " 'Product    Ethylbenzene',\n",
       " 'Product    P-Xylene',\n",
       " 'Product    M-Xylene',\n",
       " 'Product    O-Xylene',\n",
       " 'Product    n-Nonane',\n",
       " 'Product    C9 i-Paraffins',\n",
       " 'Product    C9 Naphthenes',\n",
       " 'Product    C9 Aromtics',\n",
       " 'Product    C10+ n-Paraffins',\n",
       " 'Product    C10+ i-Paraffins',\n",
       " 'Product    C10+ Naphthenes',\n",
       " 'Product    C10+ Aromtics']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_col = []\n",
    "for i in script.split('\\n'):\n",
    "    if ('[' in i)&(']'in i)&('Product' in i):\n",
    "        s = i.index('[\"')+2\n",
    "        e = i.index('\"]')\n",
    "        y_col.append(i[s:e])\n",
    "y_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get  cleaned data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((576, 43), (576, 33), (20, 43), (20, 33))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train = data[x_col]\n",
    "X_test = testdata[x_col]\n",
    "y_train = data[y_col]\n",
    "y_test = testdata[y_col]\n",
    "X_train.shape,y_train.shape,X_test.shape,y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# group x_col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "sum_col = ['Feed    Methane','Feed    Ethane','Feed    n-Butane',\n",
    "          'Feed    i-Butane','Feed    C4 Naphthenes','Feed    n-Pentane','Feed    C5 i-Paraffins',\n",
    "          'Feed    C5 Naphthenes','Feed    C6 i-Paraffins']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(576, 43)\n",
      "(576, 34)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "X_train['Feed    C6 i-Paraffins'] = X_train[sum_col].sum(axis=1)\n",
    "X_train = X_train.drop(sum_col,axis=1)\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 43)\n",
      "(20, 34)\n"
     ]
    }
   ],
   "source": [
    "print(X_test.shape)\n",
    "X_test['Feed    C6 i-Paraffins'] = X_test[sum_col].sum(axis=1)\n",
    "X_test = X_test.drop(sum_col,axis=1)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "34\n"
     ]
    }
   ],
   "source": [
    "x_col = X_train.columns.tolist()\n",
    "print(len(x_col))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# scale data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mm_x = MinMaxScaler()\n",
    "mm_x.fit(X_train.append(X_test))\n",
    "\n",
    "mm_y = MinMaxScaler()\n",
    "mm_y.fit(y_train.append(y_test))\n",
    "\n",
    "X_train[:] = mm_x.transform(X_train[:])\n",
    "X_test[:] = mm_x.transform(X_test[:])\n",
    "\n",
    "y_train[:] = mm_y.transform(y_train[:])\n",
    "y_test[:] = mm_y.transform(y_test[:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# torch data_iter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = torch.tensor(X_train.values,dtype=torch.float).cuda()\n",
    "X_test = torch.tensor(X_test.values,dtype=torch.float).cuda()\n",
    "\n",
    "y_train = torch.tensor(y_train.values,dtype=torch.float).cuda()\n",
    "y_test = torch.tensor(y_test.values,dtype=torch.float).cuda()\n",
    "\n",
    "datasets = torch.utils.data.TensorDataset(X_train, y_train)\n",
    "train_iter = torch.utils.data.DataLoader(datasets, batch_size=128,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# define model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class model4333(nn.Module):\n",
    "    def __init__(self,input_shape,output_shape):\n",
    "        super(model4333,self).__init__()\n",
    "        self.fc1 = Linear(input_shape,256)\n",
    "        self.fc2 = Linear(256,128)\n",
    "        self.fc3 = Linear(128,output_shape)\n",
    "        self.dropout = Dropout(0.5)\n",
    "    \n",
    "    def forward(self,x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.sigmoid(self.fc3(x))\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if hasattr(m,'weight'):\n",
    "        torch.nn.init.xavier_uniform(m.weight)\n",
    "    if hasattr(m,'bias'):\n",
    "        m.bias.data.fill_(0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "model4333(\n",
       "  (fc1): Linear(in_features=34, out_features=256, bias=True)\n",
       "  (fc2): Linear(in_features=256, out_features=128, bias=True)\n",
       "  (fc3): Linear(in_features=128, out_features=33, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net = model4333(len(x_col),len(y_col)).cuda()\n",
    "net.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.5127, 0.4926, 0.5527, 0.5425, 0.4309, 0.4608, 0.3666, 0.4740, 0.4103,\n",
       "        0.4084, 0.3806, 0.4677, 0.4888, 0.5506, 0.5081, 0.5052, 0.5058, 0.5226,\n",
       "        0.5664, 0.4433, 0.6284, 0.5066, 0.5542, 0.4302, 0.5551, 0.4322, 0.5239,\n",
       "        0.4444, 0.5485, 0.4973, 0.5051, 0.4203, 0.5588], device='cuda:0',\n",
       "       grad_fn=<SigmoidBackward>)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "net(X_test[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# loss and opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_function = nn.MSELoss()\n",
    "optimizer = optim.Adam(net.parameters(),lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(net,train_iter,valid_iter,loss_function,optimizer,num_epochs=100):\n",
    "    train_history = []\n",
    "    valid_history = []\n",
    "    best_loss = np.inf\n",
    "    best_net = None\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # train\n",
    "        net.train()\n",
    "        train_loss = 0\n",
    "        t = 0\n",
    "        for x,y in train_iter:\n",
    "            loss = loss_function(net(x),y)\n",
    "            \n",
    "            # weight update\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # record loss\n",
    "            train_loss += loss.item()\n",
    "            t += 1\n",
    "        train_history.append(train_loss/t)\n",
    "        \n",
    "        # eval\n",
    "        net.eval()\n",
    "        valid_loss = 0\n",
    "        t = 0\n",
    "        for x,y in valid_iter:\n",
    "            loss = loss_function(net(x),y)\n",
    "            # record loss\n",
    "            valid_loss += loss.item()\n",
    "            t += 1\n",
    "        valid_history.append(valid_loss/t)\n",
    "        \n",
    "        # print the epoch loss\n",
    "        print(\"epochs {} train loss {:.4f} valid loss {:.4f}\".format(\n",
    "            epoch,train_history[-1],valid_history[-1]))\n",
    "        \n",
    "        # record best_net\n",
    "        if valid_history[-1] <= best_loss:\n",
    "            best_loss = valid_history[-1]\n",
    "            best_net = net\n",
    "            print('record net')\n",
    "    \n",
    "    # when end all epoch plot history\n",
    "    plt.plot(np.array(train_history),label='train')\n",
    "    plt.plot(np.array(valid_history),label='valid')\n",
    "    plt.title('loss history')\n",
    "    plt.legend()\n",
    "    plt.show()\n",
    "    \n",
    "    # return best_net\n",
    "    return best_net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 0 train loss 0.0589 valid loss 0.0477\n",
      "record net\n",
      "epochs 1 train loss 0.0448 valid loss 0.0337\n",
      "record net\n",
      "epochs 2 train loss 0.0364 valid loss 0.0249\n",
      "record net\n",
      "epochs 3 train loss 0.0316 valid loss 0.0205\n",
      "record net\n",
      "epochs 4 train loss 0.0289 valid loss 0.0189\n",
      "record net\n",
      "epochs 5 train loss 0.0268 valid loss 0.0185\n",
      "record net\n",
      "epochs 6 train loss 0.0249 valid loss 0.0182\n",
      "record net\n",
      "epochs 7 train loss 0.0235 valid loss 0.0175\n",
      "record net\n",
      "epochs 8 train loss 0.0222 valid loss 0.0167\n",
      "record net\n",
      "epochs 9 train loss 0.0211 valid loss 0.0157\n",
      "record net\n",
      "epochs 10 train loss 0.0207 valid loss 0.0155\n",
      "record net\n",
      "epochs 11 train loss 0.0199 valid loss 0.0149\n",
      "record net\n",
      "epochs 12 train loss 0.0191 valid loss 0.0143\n",
      "record net\n",
      "epochs 13 train loss 0.0184 valid loss 0.0141\n",
      "record net\n",
      "epochs 14 train loss 0.0177 valid loss 0.0137\n",
      "record net\n",
      "epochs 15 train loss 0.0177 valid loss 0.0132\n",
      "record net\n",
      "epochs 16 train loss 0.0169 valid loss 0.0130\n",
      "record net\n",
      "epochs 17 train loss 0.0166 valid loss 0.0126\n",
      "record net\n",
      "epochs 18 train loss 0.0166 valid loss 0.0124\n",
      "record net\n",
      "epochs 19 train loss 0.0159 valid loss 0.0122\n",
      "record net\n",
      "epochs 20 train loss 0.0155 valid loss 0.0119\n",
      "record net\n",
      "epochs 21 train loss 0.0152 valid loss 0.0115\n",
      "record net\n",
      "epochs 22 train loss 0.0150 valid loss 0.0112\n",
      "record net\n",
      "epochs 23 train loss 0.0153 valid loss 0.0113\n",
      "epochs 24 train loss 0.0145 valid loss 0.0109\n",
      "record net\n",
      "epochs 25 train loss 0.0145 valid loss 0.0108\n",
      "record net\n",
      "epochs 26 train loss 0.0140 valid loss 0.0109\n",
      "epochs 27 train loss 0.0144 valid loss 0.0106\n",
      "record net\n",
      "epochs 28 train loss 0.0139 valid loss 0.0109\n",
      "epochs 29 train loss 0.0137 valid loss 0.0104\n",
      "record net\n",
      "epochs 30 train loss 0.0138 valid loss 0.0103\n",
      "record net\n",
      "epochs 31 train loss 0.0137 valid loss 0.0103\n",
      "record net\n",
      "epochs 32 train loss 0.0133 valid loss 0.0101\n",
      "record net\n",
      "epochs 33 train loss 0.0134 valid loss 0.0100\n",
      "record net\n",
      "epochs 34 train loss 0.0129 valid loss 0.0101\n",
      "epochs 35 train loss 0.0128 valid loss 0.0099\n",
      "record net\n",
      "epochs 36 train loss 0.0125 valid loss 0.0098\n",
      "record net\n",
      "epochs 37 train loss 0.0131 valid loss 0.0098\n",
      "epochs 38 train loss 0.0126 valid loss 0.0097\n",
      "record net\n",
      "epochs 39 train loss 0.0126 valid loss 0.0096\n",
      "record net\n",
      "epochs 40 train loss 0.0123 valid loss 0.0097\n",
      "epochs 41 train loss 0.0123 valid loss 0.0097\n",
      "epochs 42 train loss 0.0123 valid loss 0.0094\n",
      "record net\n",
      "epochs 43 train loss 0.0123 valid loss 0.0094\n",
      "record net\n",
      "epochs 44 train loss 0.0121 valid loss 0.0093\n",
      "record net\n",
      "epochs 45 train loss 0.0122 valid loss 0.0091\n",
      "record net\n",
      "epochs 46 train loss 0.0121 valid loss 0.0093\n",
      "epochs 47 train loss 0.0117 valid loss 0.0090\n",
      "record net\n",
      "epochs 48 train loss 0.0114 valid loss 0.0090\n",
      "epochs 49 train loss 0.0116 valid loss 0.0094\n",
      "epochs 50 train loss 0.0114 valid loss 0.0089\n",
      "record net\n",
      "epochs 51 train loss 0.0115 valid loss 0.0090\n",
      "epochs 52 train loss 0.0116 valid loss 0.0089\n",
      "record net\n",
      "epochs 53 train loss 0.0117 valid loss 0.0092\n",
      "epochs 54 train loss 0.0112 valid loss 0.0089\n",
      "record net\n",
      "epochs 55 train loss 0.0111 valid loss 0.0087\n",
      "record net\n",
      "epochs 56 train loss 0.0113 valid loss 0.0087\n",
      "epochs 57 train loss 0.0110 valid loss 0.0086\n",
      "record net\n",
      "epochs 58 train loss 0.0112 valid loss 0.0086\n",
      "record net\n",
      "epochs 59 train loss 0.0111 valid loss 0.0087\n",
      "epochs 60 train loss 0.0108 valid loss 0.0085\n",
      "record net\n",
      "epochs 61 train loss 0.0111 valid loss 0.0085\n",
      "record net\n",
      "epochs 62 train loss 0.0113 valid loss 0.0084\n",
      "record net\n",
      "epochs 63 train loss 0.0108 valid loss 0.0085\n",
      "epochs 64 train loss 0.0109 valid loss 0.0086\n",
      "epochs 65 train loss 0.0110 valid loss 0.0083\n",
      "record net\n",
      "epochs 66 train loss 0.0109 valid loss 0.0085\n",
      "epochs 67 train loss 0.0110 valid loss 0.0083\n",
      "record net\n",
      "epochs 68 train loss 0.0110 valid loss 0.0084\n",
      "epochs 69 train loss 0.0108 valid loss 0.0082\n",
      "record net\n",
      "epochs 70 train loss 0.0109 valid loss 0.0082\n",
      "record net\n",
      "epochs 71 train loss 0.0105 valid loss 0.0082\n",
      "epochs 72 train loss 0.0107 valid loss 0.0081\n",
      "record net\n",
      "epochs 73 train loss 0.0109 valid loss 0.0082\n",
      "epochs 74 train loss 0.0107 valid loss 0.0082\n",
      "epochs 75 train loss 0.0106 valid loss 0.0081\n",
      "epochs 76 train loss 0.0104 valid loss 0.0081\n",
      "epochs 77 train loss 0.0106 valid loss 0.0082\n",
      "epochs 78 train loss 0.0102 valid loss 0.0080\n",
      "record net\n",
      "epochs 79 train loss 0.0104 valid loss 0.0080\n",
      "epochs 80 train loss 0.0103 valid loss 0.0081\n",
      "epochs 81 train loss 0.0102 valid loss 0.0079\n",
      "record net\n",
      "epochs 82 train loss 0.0104 valid loss 0.0080\n",
      "epochs 83 train loss 0.0105 valid loss 0.0077\n",
      "record net\n",
      "epochs 84 train loss 0.0103 valid loss 0.0077\n",
      "epochs 85 train loss 0.0101 valid loss 0.0078\n",
      "epochs 86 train loss 0.0100 valid loss 0.0079\n",
      "epochs 87 train loss 0.0103 valid loss 0.0081\n",
      "epochs 88 train loss 0.0104 valid loss 0.0079\n",
      "epochs 89 train loss 0.0100 valid loss 0.0079\n",
      "epochs 90 train loss 0.0101 valid loss 0.0079\n",
      "epochs 91 train loss 0.0099 valid loss 0.0077\n",
      "record net\n",
      "epochs 92 train loss 0.0102 valid loss 0.0079\n",
      "epochs 93 train loss 0.0100 valid loss 0.0077\n",
      "epochs 94 train loss 0.0103 valid loss 0.0078\n",
      "epochs 95 train loss 0.0098 valid loss 0.0077\n",
      "record net\n",
      "epochs 96 train loss 0.0100 valid loss 0.0077\n",
      "epochs 97 train loss 0.0100 valid loss 0.0078\n",
      "epochs 98 train loss 0.0102 valid loss 0.0078\n",
      "epochs 99 train loss 0.0100 valid loss 0.0076\n",
      "record net\n",
      "epochs 100 train loss 0.0098 valid loss 0.0077\n",
      "epochs 101 train loss 0.0096 valid loss 0.0074\n",
      "record net\n",
      "epochs 102 train loss 0.0096 valid loss 0.0074\n",
      "record net\n",
      "epochs 103 train loss 0.0097 valid loss 0.0075\n",
      "epochs 104 train loss 0.0096 valid loss 0.0073\n",
      "record net\n",
      "epochs 105 train loss 0.0095 valid loss 0.0074\n",
      "epochs 106 train loss 0.0097 valid loss 0.0075\n",
      "epochs 107 train loss 0.0093 valid loss 0.0073\n",
      "epochs 108 train loss 0.0097 valid loss 0.0073\n",
      "record net\n",
      "epochs 109 train loss 0.0096 valid loss 0.0072\n",
      "record net\n",
      "epochs 110 train loss 0.0098 valid loss 0.0073\n",
      "epochs 111 train loss 0.0094 valid loss 0.0074\n",
      "epochs 112 train loss 0.0095 valid loss 0.0074\n",
      "epochs 113 train loss 0.0094 valid loss 0.0072\n",
      "record net\n",
      "epochs 114 train loss 0.0097 valid loss 0.0074\n",
      "epochs 115 train loss 0.0095 valid loss 0.0076\n",
      "epochs 116 train loss 0.0097 valid loss 0.0073\n",
      "epochs 117 train loss 0.0096 valid loss 0.0074\n",
      "epochs 118 train loss 0.0096 valid loss 0.0074\n",
      "epochs 119 train loss 0.0094 valid loss 0.0073\n",
      "epochs 120 train loss 0.0098 valid loss 0.0072\n",
      "epochs 121 train loss 0.0094 valid loss 0.0072\n",
      "record net\n",
      "epochs 122 train loss 0.0093 valid loss 0.0072\n",
      "epochs 123 train loss 0.0096 valid loss 0.0071\n",
      "record net\n",
      "epochs 124 train loss 0.0093 valid loss 0.0073\n",
      "epochs 125 train loss 0.0093 valid loss 0.0071\n",
      "record net\n",
      "epochs 126 train loss 0.0091 valid loss 0.0070\n",
      "record net\n",
      "epochs 127 train loss 0.0092 valid loss 0.0070\n",
      "epochs 128 train loss 0.0093 valid loss 0.0069\n",
      "record net\n",
      "epochs 129 train loss 0.0088 valid loss 0.0069\n",
      "epochs 130 train loss 0.0091 valid loss 0.0069\n",
      "epochs 131 train loss 0.0096 valid loss 0.0070\n",
      "epochs 132 train loss 0.0092 valid loss 0.0069\n",
      "epochs 133 train loss 0.0091 valid loss 0.0069\n",
      "epochs 134 train loss 0.0093 valid loss 0.0069\n",
      "epochs 135 train loss 0.0091 valid loss 0.0070\n",
      "epochs 136 train loss 0.0090 valid loss 0.0070\n",
      "epochs 137 train loss 0.0093 valid loss 0.0070\n",
      "epochs 138 train loss 0.0090 valid loss 0.0070\n",
      "epochs 139 train loss 0.0093 valid loss 0.0069\n",
      "epochs 140 train loss 0.0092 valid loss 0.0068\n",
      "record net\n",
      "epochs 141 train loss 0.0091 valid loss 0.0069\n",
      "epochs 142 train loss 0.0092 valid loss 0.0069\n",
      "epochs 143 train loss 0.0090 valid loss 0.0068\n",
      "record net\n",
      "epochs 144 train loss 0.0090 valid loss 0.0067\n",
      "record net\n",
      "epochs 145 train loss 0.0090 valid loss 0.0069\n",
      "epochs 146 train loss 0.0091 valid loss 0.0067\n",
      "record net\n",
      "epochs 147 train loss 0.0089 valid loss 0.0068\n",
      "epochs 148 train loss 0.0091 valid loss 0.0068\n",
      "epochs 149 train loss 0.0092 valid loss 0.0069\n",
      "epochs 150 train loss 0.0089 valid loss 0.0067\n",
      "epochs 151 train loss 0.0088 valid loss 0.0067\n",
      "record net\n",
      "epochs 152 train loss 0.0087 valid loss 0.0066\n",
      "record net\n",
      "epochs 153 train loss 0.0087 valid loss 0.0065\n",
      "record net\n",
      "epochs 154 train loss 0.0087 valid loss 0.0065\n",
      "epochs 155 train loss 0.0088 valid loss 0.0066\n",
      "epochs 156 train loss 0.0090 valid loss 0.0068\n",
      "epochs 157 train loss 0.0087 valid loss 0.0066\n",
      "epochs 158 train loss 0.0086 valid loss 0.0067\n",
      "epochs 159 train loss 0.0090 valid loss 0.0066\n",
      "epochs 160 train loss 0.0087 valid loss 0.0066\n",
      "epochs 161 train loss 0.0092 valid loss 0.0066\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 162 train loss 0.0089 valid loss 0.0066\n",
      "epochs 163 train loss 0.0089 valid loss 0.0064\n",
      "record net\n",
      "epochs 164 train loss 0.0089 valid loss 0.0066\n",
      "epochs 165 train loss 0.0088 valid loss 0.0065\n",
      "epochs 166 train loss 0.0088 valid loss 0.0067\n",
      "epochs 167 train loss 0.0088 valid loss 0.0065\n",
      "epochs 168 train loss 0.0088 valid loss 0.0065\n",
      "epochs 169 train loss 0.0090 valid loss 0.0066\n",
      "epochs 170 train loss 0.0088 valid loss 0.0064\n",
      "epochs 171 train loss 0.0088 valid loss 0.0066\n",
      "epochs 172 train loss 0.0087 valid loss 0.0065\n",
      "epochs 173 train loss 0.0088 valid loss 0.0068\n",
      "epochs 174 train loss 0.0087 valid loss 0.0065\n",
      "epochs 175 train loss 0.0086 valid loss 0.0065\n",
      "epochs 176 train loss 0.0086 valid loss 0.0064\n",
      "record net\n",
      "epochs 177 train loss 0.0090 valid loss 0.0063\n",
      "record net\n",
      "epochs 178 train loss 0.0085 valid loss 0.0064\n",
      "epochs 179 train loss 0.0086 valid loss 0.0066\n",
      "epochs 180 train loss 0.0086 valid loss 0.0064\n",
      "epochs 181 train loss 0.0086 valid loss 0.0064\n",
      "epochs 182 train loss 0.0086 valid loss 0.0063\n",
      "record net\n",
      "epochs 183 train loss 0.0085 valid loss 0.0065\n",
      "epochs 184 train loss 0.0086 valid loss 0.0064\n",
      "epochs 185 train loss 0.0086 valid loss 0.0064\n",
      "epochs 186 train loss 0.0084 valid loss 0.0063\n",
      "epochs 187 train loss 0.0083 valid loss 0.0063\n",
      "record net\n",
      "epochs 188 train loss 0.0086 valid loss 0.0063\n",
      "epochs 189 train loss 0.0085 valid loss 0.0064\n",
      "epochs 190 train loss 0.0085 valid loss 0.0063\n",
      "epochs 191 train loss 0.0083 valid loss 0.0063\n",
      "epochs 192 train loss 0.0086 valid loss 0.0063\n",
      "record net\n",
      "epochs 193 train loss 0.0082 valid loss 0.0062\n",
      "record net\n",
      "epochs 194 train loss 0.0085 valid loss 0.0062\n",
      "record net\n",
      "epochs 195 train loss 0.0085 valid loss 0.0062\n",
      "epochs 196 train loss 0.0086 valid loss 0.0063\n",
      "epochs 197 train loss 0.0084 valid loss 0.0064\n",
      "epochs 198 train loss 0.0084 valid loss 0.0061\n",
      "record net\n",
      "epochs 199 train loss 0.0082 valid loss 0.0062\n",
      "epochs 200 train loss 0.0085 valid loss 0.0062\n",
      "epochs 201 train loss 0.0081 valid loss 0.0060\n",
      "record net\n",
      "epochs 202 train loss 0.0082 valid loss 0.0063\n",
      "epochs 203 train loss 0.0085 valid loss 0.0060\n",
      "record net\n",
      "epochs 204 train loss 0.0083 valid loss 0.0061\n",
      "epochs 205 train loss 0.0085 valid loss 0.0061\n",
      "epochs 206 train loss 0.0081 valid loss 0.0064\n",
      "epochs 207 train loss 0.0084 valid loss 0.0062\n",
      "epochs 208 train loss 0.0081 valid loss 0.0062\n",
      "epochs 209 train loss 0.0083 valid loss 0.0062\n",
      "epochs 210 train loss 0.0085 valid loss 0.0060\n",
      "epochs 211 train loss 0.0082 valid loss 0.0061\n",
      "epochs 212 train loss 0.0080 valid loss 0.0061\n",
      "epochs 213 train loss 0.0082 valid loss 0.0061\n",
      "epochs 214 train loss 0.0080 valid loss 0.0061\n",
      "epochs 215 train loss 0.0082 valid loss 0.0060\n",
      "epochs 216 train loss 0.0082 valid loss 0.0060\n",
      "epochs 217 train loss 0.0082 valid loss 0.0060\n",
      "record net\n",
      "epochs 218 train loss 0.0083 valid loss 0.0061\n",
      "epochs 219 train loss 0.0084 valid loss 0.0060\n",
      "epochs 220 train loss 0.0081 valid loss 0.0062\n",
      "epochs 221 train loss 0.0082 valid loss 0.0059\n",
      "record net\n",
      "epochs 222 train loss 0.0082 valid loss 0.0059\n",
      "epochs 223 train loss 0.0082 valid loss 0.0059\n",
      "epochs 224 train loss 0.0083 valid loss 0.0059\n",
      "record net\n",
      "epochs 225 train loss 0.0082 valid loss 0.0061\n",
      "epochs 226 train loss 0.0081 valid loss 0.0060\n",
      "epochs 227 train loss 0.0083 valid loss 0.0059\n",
      "epochs 228 train loss 0.0082 valid loss 0.0061\n",
      "epochs 229 train loss 0.0083 valid loss 0.0061\n",
      "epochs 230 train loss 0.0083 valid loss 0.0059\n",
      "epochs 231 train loss 0.0083 valid loss 0.0059\n",
      "epochs 232 train loss 0.0082 valid loss 0.0061\n",
      "epochs 233 train loss 0.0080 valid loss 0.0057\n",
      "record net\n",
      "epochs 234 train loss 0.0082 valid loss 0.0060\n",
      "epochs 235 train loss 0.0079 valid loss 0.0058\n",
      "epochs 236 train loss 0.0079 valid loss 0.0061\n",
      "epochs 237 train loss 0.0083 valid loss 0.0058\n",
      "epochs 238 train loss 0.0079 valid loss 0.0057\n",
      "record net\n",
      "epochs 239 train loss 0.0079 valid loss 0.0059\n",
      "epochs 240 train loss 0.0080 valid loss 0.0058\n",
      "epochs 241 train loss 0.0079 valid loss 0.0058\n",
      "epochs 242 train loss 0.0080 valid loss 0.0059\n",
      "epochs 243 train loss 0.0082 valid loss 0.0059\n",
      "epochs 244 train loss 0.0079 valid loss 0.0060\n",
      "epochs 245 train loss 0.0080 valid loss 0.0060\n",
      "epochs 246 train loss 0.0080 valid loss 0.0058\n",
      "epochs 247 train loss 0.0079 valid loss 0.0058\n",
      "epochs 248 train loss 0.0080 valid loss 0.0057\n",
      "epochs 249 train loss 0.0078 valid loss 0.0057\n",
      "record net\n",
      "epochs 250 train loss 0.0080 valid loss 0.0057\n",
      "epochs 251 train loss 0.0079 valid loss 0.0059\n",
      "epochs 252 train loss 0.0081 valid loss 0.0057\n",
      "epochs 253 train loss 0.0081 valid loss 0.0057\n",
      "epochs 254 train loss 0.0079 valid loss 0.0058\n",
      "epochs 255 train loss 0.0080 valid loss 0.0057\n",
      "epochs 256 train loss 0.0080 valid loss 0.0056\n",
      "record net\n",
      "epochs 257 train loss 0.0080 valid loss 0.0056\n",
      "epochs 258 train loss 0.0077 valid loss 0.0057\n",
      "epochs 259 train loss 0.0081 valid loss 0.0057\n",
      "epochs 260 train loss 0.0079 valid loss 0.0058\n",
      "epochs 261 train loss 0.0078 valid loss 0.0056\n",
      "epochs 262 train loss 0.0078 valid loss 0.0059\n",
      "epochs 263 train loss 0.0079 valid loss 0.0057\n",
      "epochs 264 train loss 0.0077 valid loss 0.0057\n",
      "epochs 265 train loss 0.0076 valid loss 0.0056\n",
      "record net\n",
      "epochs 266 train loss 0.0077 valid loss 0.0059\n",
      "epochs 267 train loss 0.0082 valid loss 0.0057\n",
      "epochs 268 train loss 0.0078 valid loss 0.0056\n",
      "record net\n",
      "epochs 269 train loss 0.0078 valid loss 0.0056\n",
      "epochs 270 train loss 0.0079 valid loss 0.0056\n",
      "epochs 271 train loss 0.0077 valid loss 0.0055\n",
      "record net\n",
      "epochs 272 train loss 0.0078 valid loss 0.0056\n",
      "epochs 273 train loss 0.0079 valid loss 0.0056\n",
      "epochs 274 train loss 0.0077 valid loss 0.0056\n",
      "epochs 275 train loss 0.0079 valid loss 0.0055\n",
      "record net\n",
      "epochs 276 train loss 0.0075 valid loss 0.0054\n",
      "record net\n",
      "epochs 277 train loss 0.0075 valid loss 0.0055\n",
      "epochs 278 train loss 0.0078 valid loss 0.0056\n",
      "epochs 279 train loss 0.0080 valid loss 0.0056\n",
      "epochs 280 train loss 0.0078 valid loss 0.0056\n",
      "epochs 281 train loss 0.0076 valid loss 0.0055\n",
      "epochs 282 train loss 0.0079 valid loss 0.0055\n",
      "epochs 283 train loss 0.0075 valid loss 0.0055\n",
      "epochs 284 train loss 0.0075 valid loss 0.0054\n",
      "record net\n",
      "epochs 285 train loss 0.0075 valid loss 0.0054\n",
      "record net\n",
      "epochs 286 train loss 0.0077 valid loss 0.0055\n",
      "epochs 287 train loss 0.0076 valid loss 0.0056\n",
      "epochs 288 train loss 0.0076 valid loss 0.0056\n",
      "epochs 289 train loss 0.0078 valid loss 0.0055\n",
      "epochs 290 train loss 0.0074 valid loss 0.0055\n",
      "epochs 291 train loss 0.0076 valid loss 0.0056\n",
      "epochs 292 train loss 0.0077 valid loss 0.0055\n",
      "epochs 293 train loss 0.0076 valid loss 0.0056\n",
      "epochs 294 train loss 0.0076 valid loss 0.0055\n",
      "epochs 295 train loss 0.0079 valid loss 0.0054\n",
      "epochs 296 train loss 0.0078 valid loss 0.0054\n",
      "epochs 297 train loss 0.0077 valid loss 0.0054\n",
      "epochs 298 train loss 0.0079 valid loss 0.0054\n",
      "epochs 299 train loss 0.0076 valid loss 0.0055\n",
      "epochs 300 train loss 0.0076 valid loss 0.0056\n",
      "epochs 301 train loss 0.0075 valid loss 0.0055\n",
      "epochs 302 train loss 0.0076 valid loss 0.0056\n",
      "epochs 303 train loss 0.0080 valid loss 0.0054\n",
      "epochs 304 train loss 0.0076 valid loss 0.0055\n",
      "epochs 305 train loss 0.0075 valid loss 0.0054\n",
      "epochs 306 train loss 0.0075 valid loss 0.0056\n",
      "epochs 307 train loss 0.0076 valid loss 0.0054\n",
      "epochs 308 train loss 0.0076 valid loss 0.0054\n",
      "epochs 309 train loss 0.0075 valid loss 0.0054\n",
      "epochs 310 train loss 0.0077 valid loss 0.0054\n",
      "epochs 311 train loss 0.0076 valid loss 0.0055\n",
      "epochs 312 train loss 0.0076 valid loss 0.0052\n",
      "record net\n",
      "epochs 313 train loss 0.0076 valid loss 0.0056\n",
      "epochs 314 train loss 0.0079 valid loss 0.0057\n",
      "epochs 315 train loss 0.0076 valid loss 0.0055\n",
      "epochs 316 train loss 0.0077 valid loss 0.0053\n",
      "epochs 317 train loss 0.0073 valid loss 0.0053\n",
      "epochs 318 train loss 0.0076 valid loss 0.0052\n",
      "record net\n",
      "epochs 319 train loss 0.0074 valid loss 0.0054\n",
      "epochs 320 train loss 0.0077 valid loss 0.0054\n",
      "epochs 321 train loss 0.0076 valid loss 0.0053\n",
      "epochs 322 train loss 0.0073 valid loss 0.0053\n",
      "epochs 323 train loss 0.0074 valid loss 0.0053\n",
      "epochs 324 train loss 0.0077 valid loss 0.0053\n",
      "epochs 325 train loss 0.0073 valid loss 0.0053\n",
      "epochs 326 train loss 0.0073 valid loss 0.0053\n",
      "epochs 327 train loss 0.0076 valid loss 0.0054\n",
      "epochs 328 train loss 0.0073 valid loss 0.0053\n",
      "epochs 329 train loss 0.0074 valid loss 0.0053\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 330 train loss 0.0075 valid loss 0.0052\n",
      "record net\n",
      "epochs 331 train loss 0.0073 valid loss 0.0052\n",
      "epochs 332 train loss 0.0073 valid loss 0.0052\n",
      "record net\n",
      "epochs 333 train loss 0.0073 valid loss 0.0051\n",
      "record net\n",
      "epochs 334 train loss 0.0070 valid loss 0.0051\n",
      "epochs 335 train loss 0.0073 valid loss 0.0051\n",
      "epochs 336 train loss 0.0075 valid loss 0.0052\n",
      "epochs 337 train loss 0.0073 valid loss 0.0052\n",
      "epochs 338 train loss 0.0072 valid loss 0.0052\n",
      "epochs 339 train loss 0.0073 valid loss 0.0052\n",
      "epochs 340 train loss 0.0073 valid loss 0.0052\n",
      "epochs 341 train loss 0.0072 valid loss 0.0052\n",
      "epochs 342 train loss 0.0073 valid loss 0.0051\n",
      "epochs 343 train loss 0.0075 valid loss 0.0051\n",
      "epochs 344 train loss 0.0076 valid loss 0.0052\n",
      "epochs 345 train loss 0.0073 valid loss 0.0052\n",
      "epochs 346 train loss 0.0074 valid loss 0.0053\n",
      "epochs 347 train loss 0.0075 valid loss 0.0053\n",
      "epochs 348 train loss 0.0074 valid loss 0.0051\n",
      "epochs 349 train loss 0.0073 valid loss 0.0051\n",
      "record net\n",
      "epochs 350 train loss 0.0071 valid loss 0.0051\n",
      "epochs 351 train loss 0.0073 valid loss 0.0050\n",
      "record net\n",
      "epochs 352 train loss 0.0072 valid loss 0.0053\n",
      "epochs 353 train loss 0.0072 valid loss 0.0054\n",
      "epochs 354 train loss 0.0074 valid loss 0.0051\n",
      "epochs 355 train loss 0.0073 valid loss 0.0050\n",
      "epochs 356 train loss 0.0073 valid loss 0.0051\n",
      "epochs 357 train loss 0.0073 valid loss 0.0050\n",
      "record net\n",
      "epochs 358 train loss 0.0072 valid loss 0.0051\n",
      "epochs 359 train loss 0.0072 valid loss 0.0051\n",
      "epochs 360 train loss 0.0075 valid loss 0.0051\n",
      "epochs 361 train loss 0.0070 valid loss 0.0053\n",
      "epochs 362 train loss 0.0076 valid loss 0.0051\n",
      "epochs 363 train loss 0.0072 valid loss 0.0051\n",
      "epochs 364 train loss 0.0073 valid loss 0.0051\n",
      "epochs 365 train loss 0.0076 valid loss 0.0055\n",
      "epochs 366 train loss 0.0074 valid loss 0.0052\n",
      "epochs 367 train loss 0.0075 valid loss 0.0052\n",
      "epochs 368 train loss 0.0073 valid loss 0.0052\n",
      "epochs 369 train loss 0.0073 valid loss 0.0051\n",
      "epochs 370 train loss 0.0073 valid loss 0.0049\n",
      "record net\n",
      "epochs 371 train loss 0.0071 valid loss 0.0050\n",
      "epochs 372 train loss 0.0073 valid loss 0.0052\n",
      "epochs 373 train loss 0.0072 valid loss 0.0050\n",
      "epochs 374 train loss 0.0070 valid loss 0.0049\n",
      "epochs 375 train loss 0.0072 valid loss 0.0050\n",
      "epochs 376 train loss 0.0073 valid loss 0.0050\n",
      "epochs 377 train loss 0.0070 valid loss 0.0051\n",
      "epochs 378 train loss 0.0073 valid loss 0.0050\n",
      "epochs 379 train loss 0.0071 valid loss 0.0049\n",
      "record net\n",
      "epochs 380 train loss 0.0072 valid loss 0.0050\n",
      "epochs 381 train loss 0.0072 valid loss 0.0050\n",
      "epochs 382 train loss 0.0073 valid loss 0.0050\n",
      "epochs 383 train loss 0.0072 valid loss 0.0049\n",
      "epochs 384 train loss 0.0071 valid loss 0.0049\n",
      "epochs 385 train loss 0.0073 valid loss 0.0050\n",
      "epochs 386 train loss 0.0070 valid loss 0.0050\n",
      "epochs 387 train loss 0.0072 valid loss 0.0049\n",
      "epochs 388 train loss 0.0071 valid loss 0.0051\n",
      "epochs 389 train loss 0.0070 valid loss 0.0051\n",
      "epochs 390 train loss 0.0072 valid loss 0.0049\n",
      "epochs 391 train loss 0.0071 valid loss 0.0051\n",
      "epochs 392 train loss 0.0072 valid loss 0.0049\n",
      "record net\n",
      "epochs 393 train loss 0.0069 valid loss 0.0049\n",
      "epochs 394 train loss 0.0071 valid loss 0.0049\n",
      "epochs 395 train loss 0.0069 valid loss 0.0048\n",
      "record net\n",
      "epochs 396 train loss 0.0070 valid loss 0.0050\n",
      "epochs 397 train loss 0.0071 valid loss 0.0050\n",
      "epochs 398 train loss 0.0070 valid loss 0.0050\n",
      "epochs 399 train loss 0.0070 valid loss 0.0050\n",
      "epochs 400 train loss 0.0071 valid loss 0.0050\n",
      "epochs 401 train loss 0.0072 valid loss 0.0049\n",
      "epochs 402 train loss 0.0072 valid loss 0.0048\n",
      "record net\n",
      "epochs 403 train loss 0.0072 valid loss 0.0049\n",
      "epochs 404 train loss 0.0069 valid loss 0.0049\n",
      "epochs 405 train loss 0.0073 valid loss 0.0050\n",
      "epochs 406 train loss 0.0070 valid loss 0.0049\n",
      "epochs 407 train loss 0.0068 valid loss 0.0047\n",
      "record net\n",
      "epochs 408 train loss 0.0070 valid loss 0.0049\n",
      "epochs 409 train loss 0.0071 valid loss 0.0048\n",
      "epochs 410 train loss 0.0073 valid loss 0.0049\n",
      "epochs 411 train loss 0.0071 valid loss 0.0048\n",
      "epochs 412 train loss 0.0069 valid loss 0.0049\n",
      "epochs 413 train loss 0.0070 valid loss 0.0048\n",
      "epochs 414 train loss 0.0067 valid loss 0.0049\n",
      "epochs 415 train loss 0.0067 valid loss 0.0048\n",
      "epochs 416 train loss 0.0066 valid loss 0.0049\n",
      "epochs 417 train loss 0.0069 valid loss 0.0049\n",
      "epochs 418 train loss 0.0071 valid loss 0.0049\n",
      "epochs 419 train loss 0.0070 valid loss 0.0050\n",
      "epochs 420 train loss 0.0067 valid loss 0.0049\n",
      "epochs 421 train loss 0.0070 valid loss 0.0049\n",
      "epochs 422 train loss 0.0071 valid loss 0.0049\n",
      "epochs 423 train loss 0.0072 valid loss 0.0047\n",
      "record net\n",
      "epochs 424 train loss 0.0068 valid loss 0.0047\n",
      "epochs 425 train loss 0.0069 valid loss 0.0049\n",
      "epochs 426 train loss 0.0069 valid loss 0.0049\n",
      "epochs 427 train loss 0.0068 valid loss 0.0048\n",
      "epochs 428 train loss 0.0072 valid loss 0.0047\n",
      "epochs 429 train loss 0.0071 valid loss 0.0048\n",
      "epochs 430 train loss 0.0066 valid loss 0.0046\n",
      "record net\n",
      "epochs 431 train loss 0.0067 valid loss 0.0047\n",
      "epochs 432 train loss 0.0069 valid loss 0.0047\n",
      "epochs 433 train loss 0.0068 valid loss 0.0048\n",
      "epochs 434 train loss 0.0069 valid loss 0.0047\n",
      "epochs 435 train loss 0.0068 valid loss 0.0046\n",
      "record net\n",
      "epochs 436 train loss 0.0069 valid loss 0.0047\n",
      "epochs 437 train loss 0.0069 valid loss 0.0046\n",
      "epochs 438 train loss 0.0068 valid loss 0.0047\n",
      "epochs 439 train loss 0.0069 valid loss 0.0048\n",
      "epochs 440 train loss 0.0071 valid loss 0.0047\n",
      "epochs 441 train loss 0.0069 valid loss 0.0046\n",
      "epochs 442 train loss 0.0067 valid loss 0.0046\n",
      "epochs 443 train loss 0.0069 valid loss 0.0046\n",
      "epochs 444 train loss 0.0067 valid loss 0.0047\n",
      "epochs 445 train loss 0.0068 valid loss 0.0048\n",
      "epochs 446 train loss 0.0070 valid loss 0.0046\n",
      "epochs 447 train loss 0.0067 valid loss 0.0047\n",
      "epochs 448 train loss 0.0067 valid loss 0.0046\n",
      "epochs 449 train loss 0.0068 valid loss 0.0047\n",
      "epochs 450 train loss 0.0068 valid loss 0.0047\n",
      "epochs 451 train loss 0.0068 valid loss 0.0047\n",
      "epochs 452 train loss 0.0067 valid loss 0.0047\n",
      "epochs 453 train loss 0.0066 valid loss 0.0048\n",
      "epochs 454 train loss 0.0068 valid loss 0.0047\n",
      "epochs 455 train loss 0.0068 valid loss 0.0047\n",
      "epochs 456 train loss 0.0068 valid loss 0.0046\n",
      "epochs 457 train loss 0.0068 valid loss 0.0045\n",
      "record net\n",
      "epochs 458 train loss 0.0068 valid loss 0.0045\n",
      "record net\n",
      "epochs 459 train loss 0.0067 valid loss 0.0046\n",
      "epochs 460 train loss 0.0067 valid loss 0.0047\n",
      "epochs 461 train loss 0.0068 valid loss 0.0048\n",
      "epochs 462 train loss 0.0066 valid loss 0.0046\n",
      "epochs 463 train loss 0.0065 valid loss 0.0046\n",
      "epochs 464 train loss 0.0068 valid loss 0.0045\n",
      "record net\n",
      "epochs 465 train loss 0.0067 valid loss 0.0045\n",
      "epochs 466 train loss 0.0068 valid loss 0.0044\n",
      "record net\n",
      "epochs 467 train loss 0.0066 valid loss 0.0046\n",
      "epochs 468 train loss 0.0068 valid loss 0.0045\n",
      "epochs 469 train loss 0.0067 valid loss 0.0045\n",
      "epochs 470 train loss 0.0067 valid loss 0.0047\n",
      "epochs 471 train loss 0.0069 valid loss 0.0046\n",
      "epochs 472 train loss 0.0067 valid loss 0.0045\n",
      "epochs 473 train loss 0.0067 valid loss 0.0046\n",
      "epochs 474 train loss 0.0066 valid loss 0.0045\n",
      "epochs 475 train loss 0.0067 valid loss 0.0044\n",
      "epochs 476 train loss 0.0066 valid loss 0.0045\n",
      "epochs 477 train loss 0.0068 valid loss 0.0044\n",
      "epochs 478 train loss 0.0066 valid loss 0.0045\n",
      "epochs 479 train loss 0.0066 valid loss 0.0045\n",
      "epochs 480 train loss 0.0067 valid loss 0.0046\n",
      "epochs 481 train loss 0.0069 valid loss 0.0046\n",
      "epochs 482 train loss 0.0067 valid loss 0.0045\n",
      "epochs 483 train loss 0.0066 valid loss 0.0045\n",
      "epochs 484 train loss 0.0066 valid loss 0.0045\n",
      "epochs 485 train loss 0.0066 valid loss 0.0044\n",
      "epochs 486 train loss 0.0065 valid loss 0.0046\n",
      "epochs 487 train loss 0.0066 valid loss 0.0045\n",
      "epochs 488 train loss 0.0067 valid loss 0.0045\n",
      "epochs 489 train loss 0.0066 valid loss 0.0045\n",
      "epochs 490 train loss 0.0066 valid loss 0.0044\n",
      "epochs 491 train loss 0.0066 valid loss 0.0045\n",
      "epochs 492 train loss 0.0067 valid loss 0.0044\n",
      "epochs 493 train loss 0.0065 valid loss 0.0045\n",
      "epochs 494 train loss 0.0067 valid loss 0.0045\n",
      "epochs 495 train loss 0.0065 valid loss 0.0044\n",
      "epochs 496 train loss 0.0066 valid loss 0.0044\n",
      "epochs 497 train loss 0.0063 valid loss 0.0044\n",
      "record net\n",
      "epochs 498 train loss 0.0066 valid loss 0.0045\n",
      "epochs 499 train loss 0.0066 valid loss 0.0045\n",
      "epochs 500 train loss 0.0065 valid loss 0.0046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 501 train loss 0.0065 valid loss 0.0045\n",
      "epochs 502 train loss 0.0065 valid loss 0.0045\n",
      "epochs 503 train loss 0.0066 valid loss 0.0045\n",
      "epochs 504 train loss 0.0067 valid loss 0.0044\n",
      "record net\n",
      "epochs 505 train loss 0.0067 valid loss 0.0046\n",
      "epochs 506 train loss 0.0065 valid loss 0.0045\n",
      "epochs 507 train loss 0.0068 valid loss 0.0044\n",
      "record net\n",
      "epochs 508 train loss 0.0066 valid loss 0.0045\n",
      "epochs 509 train loss 0.0065 valid loss 0.0044\n",
      "epochs 510 train loss 0.0067 valid loss 0.0045\n",
      "epochs 511 train loss 0.0065 valid loss 0.0045\n",
      "epochs 512 train loss 0.0065 valid loss 0.0044\n",
      "epochs 513 train loss 0.0067 valid loss 0.0044\n",
      "epochs 514 train loss 0.0067 valid loss 0.0046\n",
      "epochs 515 train loss 0.0067 valid loss 0.0043\n",
      "record net\n",
      "epochs 516 train loss 0.0065 valid loss 0.0043\n",
      "epochs 517 train loss 0.0066 valid loss 0.0043\n",
      "epochs 518 train loss 0.0065 valid loss 0.0045\n",
      "epochs 519 train loss 0.0067 valid loss 0.0044\n",
      "epochs 520 train loss 0.0063 valid loss 0.0044\n",
      "epochs 521 train loss 0.0063 valid loss 0.0043\n",
      "epochs 522 train loss 0.0065 valid loss 0.0043\n",
      "epochs 523 train loss 0.0067 valid loss 0.0042\n",
      "record net\n",
      "epochs 524 train loss 0.0066 valid loss 0.0044\n",
      "epochs 525 train loss 0.0066 valid loss 0.0044\n",
      "epochs 526 train loss 0.0065 valid loss 0.0043\n",
      "epochs 527 train loss 0.0063 valid loss 0.0043\n",
      "epochs 528 train loss 0.0066 valid loss 0.0043\n",
      "epochs 529 train loss 0.0064 valid loss 0.0044\n",
      "epochs 530 train loss 0.0063 valid loss 0.0044\n",
      "epochs 531 train loss 0.0064 valid loss 0.0045\n",
      "epochs 532 train loss 0.0066 valid loss 0.0044\n",
      "epochs 533 train loss 0.0065 valid loss 0.0042\n",
      "record net\n",
      "epochs 534 train loss 0.0066 valid loss 0.0043\n",
      "epochs 535 train loss 0.0062 valid loss 0.0044\n",
      "epochs 536 train loss 0.0066 valid loss 0.0043\n",
      "epochs 537 train loss 0.0066 valid loss 0.0043\n",
      "epochs 538 train loss 0.0062 valid loss 0.0043\n",
      "epochs 539 train loss 0.0065 valid loss 0.0043\n",
      "epochs 540 train loss 0.0062 valid loss 0.0044\n",
      "epochs 541 train loss 0.0064 valid loss 0.0042\n",
      "epochs 542 train loss 0.0063 valid loss 0.0044\n",
      "epochs 543 train loss 0.0066 valid loss 0.0043\n",
      "epochs 544 train loss 0.0066 valid loss 0.0042\n",
      "epochs 545 train loss 0.0062 valid loss 0.0043\n",
      "epochs 546 train loss 0.0062 valid loss 0.0042\n",
      "record net\n",
      "epochs 547 train loss 0.0063 valid loss 0.0042\n",
      "epochs 548 train loss 0.0065 valid loss 0.0042\n",
      "record net\n",
      "epochs 549 train loss 0.0064 valid loss 0.0043\n",
      "epochs 550 train loss 0.0063 valid loss 0.0044\n",
      "epochs 551 train loss 0.0062 valid loss 0.0042\n",
      "epochs 552 train loss 0.0064 valid loss 0.0043\n",
      "epochs 553 train loss 0.0064 valid loss 0.0043\n",
      "epochs 554 train loss 0.0064 valid loss 0.0041\n",
      "record net\n",
      "epochs 555 train loss 0.0064 valid loss 0.0043\n",
      "epochs 556 train loss 0.0063 valid loss 0.0043\n",
      "epochs 557 train loss 0.0063 valid loss 0.0043\n",
      "epochs 558 train loss 0.0063 valid loss 0.0043\n",
      "epochs 559 train loss 0.0063 valid loss 0.0042\n",
      "epochs 560 train loss 0.0062 valid loss 0.0042\n",
      "epochs 561 train loss 0.0062 valid loss 0.0043\n",
      "epochs 562 train loss 0.0062 valid loss 0.0041\n",
      "epochs 563 train loss 0.0061 valid loss 0.0043\n",
      "epochs 564 train loss 0.0065 valid loss 0.0043\n",
      "epochs 565 train loss 0.0062 valid loss 0.0042\n",
      "epochs 566 train loss 0.0061 valid loss 0.0041\n",
      "record net\n",
      "epochs 567 train loss 0.0063 valid loss 0.0043\n",
      "epochs 568 train loss 0.0064 valid loss 0.0042\n",
      "epochs 569 train loss 0.0062 valid loss 0.0042\n",
      "epochs 570 train loss 0.0063 valid loss 0.0041\n",
      "epochs 571 train loss 0.0063 valid loss 0.0042\n",
      "epochs 572 train loss 0.0062 valid loss 0.0042\n",
      "epochs 573 train loss 0.0061 valid loss 0.0042\n",
      "epochs 574 train loss 0.0064 valid loss 0.0042\n",
      "epochs 575 train loss 0.0061 valid loss 0.0041\n",
      "record net\n",
      "epochs 576 train loss 0.0063 valid loss 0.0041\n",
      "record net\n",
      "epochs 577 train loss 0.0062 valid loss 0.0041\n",
      "epochs 578 train loss 0.0061 valid loss 0.0042\n",
      "epochs 579 train loss 0.0063 valid loss 0.0042\n",
      "epochs 580 train loss 0.0064 valid loss 0.0042\n",
      "epochs 581 train loss 0.0063 valid loss 0.0041\n",
      "epochs 582 train loss 0.0063 valid loss 0.0041\n",
      "record net\n",
      "epochs 583 train loss 0.0063 valid loss 0.0042\n",
      "epochs 584 train loss 0.0060 valid loss 0.0042\n",
      "epochs 585 train loss 0.0062 valid loss 0.0041\n",
      "record net\n",
      "epochs 586 train loss 0.0065 valid loss 0.0041\n",
      "epochs 587 train loss 0.0062 valid loss 0.0043\n",
      "epochs 588 train loss 0.0062 valid loss 0.0042\n",
      "epochs 589 train loss 0.0061 valid loss 0.0041\n",
      "epochs 590 train loss 0.0061 valid loss 0.0041\n",
      "epochs 591 train loss 0.0060 valid loss 0.0041\n",
      "epochs 592 train loss 0.0063 valid loss 0.0041\n",
      "epochs 593 train loss 0.0063 valid loss 0.0041\n",
      "epochs 594 train loss 0.0064 valid loss 0.0041\n",
      "epochs 595 train loss 0.0066 valid loss 0.0040\n",
      "record net\n",
      "epochs 596 train loss 0.0063 valid loss 0.0040\n",
      "epochs 597 train loss 0.0062 valid loss 0.0043\n",
      "epochs 598 train loss 0.0060 valid loss 0.0042\n",
      "epochs 599 train loss 0.0062 valid loss 0.0041\n",
      "epochs 600 train loss 0.0064 valid loss 0.0040\n",
      "epochs 601 train loss 0.0061 valid loss 0.0042\n",
      "epochs 602 train loss 0.0063 valid loss 0.0040\n",
      "epochs 603 train loss 0.0062 valid loss 0.0040\n",
      "epochs 604 train loss 0.0062 valid loss 0.0042\n",
      "epochs 605 train loss 0.0061 valid loss 0.0041\n",
      "epochs 606 train loss 0.0061 valid loss 0.0040\n",
      "epochs 607 train loss 0.0061 valid loss 0.0040\n",
      "epochs 608 train loss 0.0062 valid loss 0.0041\n",
      "epochs 609 train loss 0.0062 valid loss 0.0040\n",
      "record net\n",
      "epochs 610 train loss 0.0062 valid loss 0.0041\n",
      "epochs 611 train loss 0.0060 valid loss 0.0040\n",
      "epochs 612 train loss 0.0062 valid loss 0.0040\n",
      "epochs 613 train loss 0.0060 valid loss 0.0041\n",
      "epochs 614 train loss 0.0064 valid loss 0.0040\n",
      "epochs 615 train loss 0.0062 valid loss 0.0041\n",
      "epochs 616 train loss 0.0061 valid loss 0.0041\n",
      "epochs 617 train loss 0.0061 valid loss 0.0040\n",
      "epochs 618 train loss 0.0062 valid loss 0.0040\n",
      "epochs 619 train loss 0.0061 valid loss 0.0040\n",
      "epochs 620 train loss 0.0063 valid loss 0.0042\n",
      "epochs 621 train loss 0.0061 valid loss 0.0042\n",
      "epochs 622 train loss 0.0062 valid loss 0.0041\n",
      "epochs 623 train loss 0.0060 valid loss 0.0041\n",
      "epochs 624 train loss 0.0061 valid loss 0.0040\n",
      "epochs 625 train loss 0.0061 valid loss 0.0040\n",
      "epochs 626 train loss 0.0064 valid loss 0.0042\n",
      "epochs 627 train loss 0.0060 valid loss 0.0040\n",
      "epochs 628 train loss 0.0060 valid loss 0.0040\n",
      "record net\n",
      "epochs 629 train loss 0.0061 valid loss 0.0040\n",
      "epochs 630 train loss 0.0062 valid loss 0.0039\n",
      "record net\n",
      "epochs 631 train loss 0.0061 valid loss 0.0039\n",
      "epochs 632 train loss 0.0061 valid loss 0.0040\n",
      "epochs 633 train loss 0.0061 valid loss 0.0040\n",
      "epochs 634 train loss 0.0061 valid loss 0.0040\n",
      "epochs 635 train loss 0.0060 valid loss 0.0039\n",
      "epochs 636 train loss 0.0061 valid loss 0.0040\n",
      "epochs 637 train loss 0.0059 valid loss 0.0040\n",
      "epochs 638 train loss 0.0061 valid loss 0.0039\n",
      "epochs 639 train loss 0.0060 valid loss 0.0038\n",
      "record net\n",
      "epochs 640 train loss 0.0062 valid loss 0.0039\n",
      "epochs 641 train loss 0.0060 valid loss 0.0040\n",
      "epochs 642 train loss 0.0062 valid loss 0.0039\n",
      "epochs 643 train loss 0.0061 valid loss 0.0039\n",
      "epochs 644 train loss 0.0061 valid loss 0.0039\n",
      "epochs 645 train loss 0.0060 valid loss 0.0040\n",
      "epochs 646 train loss 0.0059 valid loss 0.0039\n",
      "epochs 647 train loss 0.0062 valid loss 0.0040\n",
      "epochs 648 train loss 0.0062 valid loss 0.0041\n",
      "epochs 649 train loss 0.0060 valid loss 0.0040\n",
      "epochs 650 train loss 0.0059 valid loss 0.0040\n",
      "epochs 651 train loss 0.0062 valid loss 0.0039\n",
      "epochs 652 train loss 0.0060 valid loss 0.0039\n",
      "epochs 653 train loss 0.0061 valid loss 0.0037\n",
      "record net\n",
      "epochs 654 train loss 0.0059 valid loss 0.0039\n",
      "epochs 655 train loss 0.0058 valid loss 0.0039\n",
      "epochs 656 train loss 0.0062 valid loss 0.0039\n",
      "epochs 657 train loss 0.0059 valid loss 0.0040\n",
      "epochs 658 train loss 0.0062 valid loss 0.0039\n",
      "epochs 659 train loss 0.0060 valid loss 0.0038\n",
      "epochs 660 train loss 0.0063 valid loss 0.0039\n",
      "epochs 661 train loss 0.0061 valid loss 0.0039\n",
      "epochs 662 train loss 0.0058 valid loss 0.0039\n",
      "epochs 663 train loss 0.0059 valid loss 0.0039\n",
      "epochs 664 train loss 0.0061 valid loss 0.0040\n",
      "epochs 665 train loss 0.0062 valid loss 0.0040\n",
      "epochs 666 train loss 0.0061 valid loss 0.0039\n",
      "epochs 667 train loss 0.0060 valid loss 0.0038\n",
      "epochs 668 train loss 0.0062 valid loss 0.0040\n",
      "epochs 669 train loss 0.0060 valid loss 0.0039\n",
      "epochs 670 train loss 0.0058 valid loss 0.0039\n",
      "epochs 671 train loss 0.0060 valid loss 0.0039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 672 train loss 0.0056 valid loss 0.0039\n",
      "epochs 673 train loss 0.0059 valid loss 0.0038\n",
      "epochs 674 train loss 0.0059 valid loss 0.0039\n",
      "epochs 675 train loss 0.0060 valid loss 0.0039\n",
      "epochs 676 train loss 0.0059 valid loss 0.0039\n",
      "epochs 677 train loss 0.0059 valid loss 0.0040\n",
      "epochs 678 train loss 0.0060 valid loss 0.0038\n",
      "epochs 679 train loss 0.0059 valid loss 0.0037\n",
      "record net\n",
      "epochs 680 train loss 0.0060 valid loss 0.0039\n",
      "epochs 681 train loss 0.0060 valid loss 0.0040\n",
      "epochs 682 train loss 0.0060 valid loss 0.0038\n",
      "epochs 683 train loss 0.0060 valid loss 0.0038\n",
      "epochs 684 train loss 0.0059 valid loss 0.0039\n",
      "epochs 685 train loss 0.0060 valid loss 0.0039\n",
      "epochs 686 train loss 0.0062 valid loss 0.0039\n",
      "epochs 687 train loss 0.0060 valid loss 0.0039\n",
      "epochs 688 train loss 0.0063 valid loss 0.0038\n",
      "epochs 689 train loss 0.0058 valid loss 0.0038\n",
      "epochs 690 train loss 0.0059 valid loss 0.0038\n",
      "epochs 691 train loss 0.0058 valid loss 0.0038\n",
      "epochs 692 train loss 0.0059 valid loss 0.0038\n",
      "epochs 693 train loss 0.0059 valid loss 0.0037\n",
      "record net\n",
      "epochs 694 train loss 0.0059 valid loss 0.0038\n",
      "epochs 695 train loss 0.0060 valid loss 0.0040\n",
      "epochs 696 train loss 0.0059 valid loss 0.0038\n",
      "epochs 697 train loss 0.0060 valid loss 0.0038\n",
      "epochs 698 train loss 0.0061 valid loss 0.0039\n",
      "epochs 699 train loss 0.0060 valid loss 0.0038\n",
      "epochs 700 train loss 0.0059 valid loss 0.0038\n",
      "epochs 701 train loss 0.0063 valid loss 0.0038\n",
      "epochs 702 train loss 0.0059 valid loss 0.0038\n",
      "epochs 703 train loss 0.0059 valid loss 0.0039\n",
      "epochs 704 train loss 0.0058 valid loss 0.0039\n",
      "epochs 705 train loss 0.0058 valid loss 0.0039\n",
      "epochs 706 train loss 0.0058 valid loss 0.0038\n",
      "epochs 707 train loss 0.0061 valid loss 0.0039\n",
      "epochs 708 train loss 0.0059 valid loss 0.0039\n",
      "epochs 709 train loss 0.0058 valid loss 0.0039\n",
      "epochs 710 train loss 0.0059 valid loss 0.0038\n",
      "epochs 711 train loss 0.0058 valid loss 0.0038\n",
      "epochs 712 train loss 0.0060 valid loss 0.0037\n",
      "epochs 713 train loss 0.0060 valid loss 0.0039\n",
      "epochs 714 train loss 0.0060 valid loss 0.0038\n",
      "epochs 715 train loss 0.0062 valid loss 0.0038\n",
      "epochs 716 train loss 0.0061 valid loss 0.0037\n",
      "record net\n",
      "epochs 717 train loss 0.0057 valid loss 0.0038\n",
      "epochs 718 train loss 0.0059 valid loss 0.0037\n",
      "epochs 719 train loss 0.0058 valid loss 0.0039\n",
      "epochs 720 train loss 0.0060 valid loss 0.0037\n",
      "epochs 721 train loss 0.0057 valid loss 0.0037\n",
      "epochs 722 train loss 0.0058 valid loss 0.0037\n",
      "epochs 723 train loss 0.0057 valid loss 0.0037\n",
      "epochs 724 train loss 0.0057 valid loss 0.0037\n",
      "epochs 725 train loss 0.0058 valid loss 0.0037\n",
      "epochs 726 train loss 0.0058 valid loss 0.0037\n",
      "epochs 727 train loss 0.0057 valid loss 0.0037\n",
      "epochs 728 train loss 0.0059 valid loss 0.0037\n",
      "epochs 729 train loss 0.0059 valid loss 0.0038\n",
      "epochs 730 train loss 0.0057 valid loss 0.0037\n",
      "epochs 731 train loss 0.0060 valid loss 0.0037\n",
      "epochs 732 train loss 0.0059 valid loss 0.0037\n",
      "epochs 733 train loss 0.0060 valid loss 0.0038\n",
      "epochs 734 train loss 0.0060 valid loss 0.0037\n",
      "epochs 735 train loss 0.0060 valid loss 0.0038\n",
      "epochs 736 train loss 0.0062 valid loss 0.0038\n",
      "epochs 737 train loss 0.0058 valid loss 0.0037\n",
      "epochs 738 train loss 0.0061 valid loss 0.0037\n",
      "record net\n",
      "epochs 739 train loss 0.0058 valid loss 0.0038\n",
      "epochs 740 train loss 0.0058 valid loss 0.0038\n",
      "epochs 741 train loss 0.0055 valid loss 0.0038\n",
      "epochs 742 train loss 0.0059 valid loss 0.0036\n",
      "record net\n",
      "epochs 743 train loss 0.0061 valid loss 0.0037\n",
      "epochs 744 train loss 0.0057 valid loss 0.0038\n",
      "epochs 745 train loss 0.0057 valid loss 0.0038\n",
      "epochs 746 train loss 0.0058 valid loss 0.0036\n",
      "record net\n",
      "epochs 747 train loss 0.0058 valid loss 0.0038\n",
      "epochs 748 train loss 0.0059 valid loss 0.0037\n",
      "epochs 749 train loss 0.0059 valid loss 0.0037\n",
      "epochs 750 train loss 0.0058 valid loss 0.0039\n",
      "epochs 751 train loss 0.0059 valid loss 0.0038\n",
      "epochs 752 train loss 0.0058 valid loss 0.0036\n",
      "record net\n",
      "epochs 753 train loss 0.0058 valid loss 0.0036\n",
      "record net\n",
      "epochs 754 train loss 0.0057 valid loss 0.0037\n",
      "epochs 755 train loss 0.0058 valid loss 0.0036\n",
      "record net\n",
      "epochs 756 train loss 0.0061 valid loss 0.0036\n",
      "epochs 757 train loss 0.0056 valid loss 0.0036\n",
      "epochs 758 train loss 0.0058 valid loss 0.0036\n",
      "epochs 759 train loss 0.0057 valid loss 0.0036\n",
      "epochs 760 train loss 0.0057 valid loss 0.0036\n",
      "record net\n",
      "epochs 761 train loss 0.0057 valid loss 0.0037\n",
      "epochs 762 train loss 0.0057 valid loss 0.0036\n",
      "record net\n",
      "epochs 763 train loss 0.0056 valid loss 0.0036\n",
      "record net\n",
      "epochs 764 train loss 0.0058 valid loss 0.0035\n",
      "record net\n",
      "epochs 765 train loss 0.0059 valid loss 0.0035\n",
      "record net\n",
      "epochs 766 train loss 0.0059 valid loss 0.0036\n",
      "epochs 767 train loss 0.0057 valid loss 0.0036\n",
      "epochs 768 train loss 0.0058 valid loss 0.0035\n",
      "record net\n",
      "epochs 769 train loss 0.0057 valid loss 0.0036\n",
      "epochs 770 train loss 0.0061 valid loss 0.0035\n",
      "epochs 771 train loss 0.0057 valid loss 0.0037\n",
      "epochs 772 train loss 0.0058 valid loss 0.0036\n",
      "epochs 773 train loss 0.0056 valid loss 0.0036\n",
      "epochs 774 train loss 0.0057 valid loss 0.0035\n",
      "epochs 775 train loss 0.0057 valid loss 0.0036\n",
      "epochs 776 train loss 0.0057 valid loss 0.0037\n",
      "epochs 777 train loss 0.0059 valid loss 0.0036\n",
      "epochs 778 train loss 0.0057 valid loss 0.0036\n",
      "epochs 779 train loss 0.0059 valid loss 0.0036\n",
      "epochs 780 train loss 0.0058 valid loss 0.0036\n",
      "epochs 781 train loss 0.0056 valid loss 0.0038\n",
      "epochs 782 train loss 0.0057 valid loss 0.0036\n",
      "epochs 783 train loss 0.0057 valid loss 0.0036\n",
      "epochs 784 train loss 0.0057 valid loss 0.0037\n",
      "epochs 785 train loss 0.0056 valid loss 0.0036\n",
      "epochs 786 train loss 0.0056 valid loss 0.0036\n",
      "epochs 787 train loss 0.0059 valid loss 0.0036\n",
      "epochs 788 train loss 0.0059 valid loss 0.0036\n",
      "epochs 789 train loss 0.0057 valid loss 0.0035\n",
      "epochs 790 train loss 0.0057 valid loss 0.0035\n",
      "record net\n",
      "epochs 791 train loss 0.0057 valid loss 0.0036\n",
      "epochs 792 train loss 0.0055 valid loss 0.0035\n",
      "epochs 793 train loss 0.0057 valid loss 0.0035\n",
      "epochs 794 train loss 0.0060 valid loss 0.0037\n",
      "epochs 795 train loss 0.0056 valid loss 0.0036\n",
      "epochs 796 train loss 0.0056 valid loss 0.0036\n",
      "epochs 797 train loss 0.0057 valid loss 0.0035\n",
      "epochs 798 train loss 0.0060 valid loss 0.0037\n",
      "epochs 799 train loss 0.0059 valid loss 0.0037\n",
      "epochs 800 train loss 0.0058 valid loss 0.0036\n",
      "epochs 801 train loss 0.0055 valid loss 0.0035\n",
      "epochs 802 train loss 0.0057 valid loss 0.0035\n",
      "epochs 803 train loss 0.0056 valid loss 0.0035\n",
      "epochs 804 train loss 0.0055 valid loss 0.0036\n",
      "epochs 805 train loss 0.0055 valid loss 0.0035\n",
      "epochs 806 train loss 0.0057 valid loss 0.0035\n",
      "record net\n",
      "epochs 807 train loss 0.0056 valid loss 0.0036\n",
      "epochs 808 train loss 0.0058 valid loss 0.0036\n",
      "epochs 809 train loss 0.0058 valid loss 0.0037\n",
      "epochs 810 train loss 0.0059 valid loss 0.0035\n",
      "epochs 811 train loss 0.0058 valid loss 0.0038\n",
      "epochs 812 train loss 0.0058 valid loss 0.0037\n",
      "epochs 813 train loss 0.0059 valid loss 0.0036\n",
      "epochs 814 train loss 0.0055 valid loss 0.0036\n",
      "epochs 815 train loss 0.0057 valid loss 0.0036\n",
      "epochs 816 train loss 0.0055 valid loss 0.0035\n",
      "epochs 817 train loss 0.0058 valid loss 0.0034\n",
      "record net\n",
      "epochs 818 train loss 0.0056 valid loss 0.0035\n",
      "epochs 819 train loss 0.0056 valid loss 0.0034\n",
      "record net\n",
      "epochs 820 train loss 0.0054 valid loss 0.0035\n",
      "epochs 821 train loss 0.0054 valid loss 0.0036\n",
      "epochs 822 train loss 0.0056 valid loss 0.0034\n",
      "record net\n",
      "epochs 823 train loss 0.0055 valid loss 0.0036\n",
      "epochs 824 train loss 0.0055 valid loss 0.0035\n",
      "epochs 825 train loss 0.0054 valid loss 0.0034\n",
      "epochs 826 train loss 0.0060 valid loss 0.0036\n",
      "epochs 827 train loss 0.0057 valid loss 0.0036\n",
      "epochs 828 train loss 0.0058 valid loss 0.0035\n",
      "epochs 829 train loss 0.0057 valid loss 0.0035\n",
      "epochs 830 train loss 0.0057 valid loss 0.0036\n",
      "epochs 831 train loss 0.0055 valid loss 0.0035\n",
      "epochs 832 train loss 0.0055 valid loss 0.0036\n",
      "epochs 833 train loss 0.0057 valid loss 0.0035\n",
      "epochs 834 train loss 0.0057 valid loss 0.0034\n",
      "epochs 835 train loss 0.0056 valid loss 0.0034\n",
      "epochs 836 train loss 0.0059 valid loss 0.0035\n",
      "epochs 837 train loss 0.0057 valid loss 0.0035\n",
      "epochs 838 train loss 0.0057 valid loss 0.0035\n",
      "epochs 839 train loss 0.0055 valid loss 0.0035\n",
      "epochs 840 train loss 0.0056 valid loss 0.0034\n",
      "epochs 841 train loss 0.0054 valid loss 0.0035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 842 train loss 0.0056 valid loss 0.0034\n",
      "epochs 843 train loss 0.0055 valid loss 0.0034\n",
      "epochs 844 train loss 0.0056 valid loss 0.0035\n",
      "epochs 845 train loss 0.0056 valid loss 0.0034\n",
      "epochs 846 train loss 0.0055 valid loss 0.0035\n",
      "epochs 847 train loss 0.0055 valid loss 0.0035\n",
      "epochs 848 train loss 0.0057 valid loss 0.0036\n",
      "epochs 849 train loss 0.0056 valid loss 0.0034\n",
      "epochs 850 train loss 0.0056 valid loss 0.0034\n",
      "epochs 851 train loss 0.0057 valid loss 0.0034\n",
      "epochs 852 train loss 0.0056 valid loss 0.0034\n",
      "epochs 853 train loss 0.0054 valid loss 0.0035\n",
      "epochs 854 train loss 0.0056 valid loss 0.0034\n",
      "epochs 855 train loss 0.0055 valid loss 0.0033\n",
      "record net\n",
      "epochs 856 train loss 0.0058 valid loss 0.0034\n",
      "epochs 857 train loss 0.0056 valid loss 0.0033\n",
      "record net\n",
      "epochs 858 train loss 0.0056 valid loss 0.0033\n",
      "epochs 859 train loss 0.0056 valid loss 0.0034\n",
      "epochs 860 train loss 0.0055 valid loss 0.0035\n",
      "epochs 861 train loss 0.0056 valid loss 0.0035\n",
      "epochs 862 train loss 0.0056 valid loss 0.0034\n",
      "epochs 863 train loss 0.0053 valid loss 0.0034\n",
      "epochs 864 train loss 0.0054 valid loss 0.0034\n",
      "epochs 865 train loss 0.0055 valid loss 0.0036\n",
      "epochs 866 train loss 0.0056 valid loss 0.0036\n",
      "epochs 867 train loss 0.0054 valid loss 0.0033\n",
      "record net\n",
      "epochs 868 train loss 0.0054 valid loss 0.0035\n",
      "epochs 869 train loss 0.0056 valid loss 0.0038\n",
      "epochs 870 train loss 0.0060 valid loss 0.0038\n",
      "epochs 871 train loss 0.0055 valid loss 0.0035\n",
      "epochs 872 train loss 0.0053 valid loss 0.0035\n",
      "epochs 873 train loss 0.0055 valid loss 0.0035\n",
      "epochs 874 train loss 0.0057 valid loss 0.0033\n",
      "epochs 875 train loss 0.0053 valid loss 0.0034\n",
      "epochs 876 train loss 0.0054 valid loss 0.0033\n",
      "record net\n",
      "epochs 877 train loss 0.0053 valid loss 0.0034\n",
      "epochs 878 train loss 0.0056 valid loss 0.0034\n",
      "epochs 879 train loss 0.0056 valid loss 0.0033\n",
      "epochs 880 train loss 0.0053 valid loss 0.0034\n",
      "epochs 881 train loss 0.0052 valid loss 0.0034\n",
      "epochs 882 train loss 0.0057 valid loss 0.0033\n",
      "epochs 883 train loss 0.0056 valid loss 0.0034\n",
      "epochs 884 train loss 0.0055 valid loss 0.0034\n",
      "epochs 885 train loss 0.0056 valid loss 0.0034\n",
      "epochs 886 train loss 0.0056 valid loss 0.0034\n",
      "epochs 887 train loss 0.0056 valid loss 0.0033\n",
      "epochs 888 train loss 0.0053 valid loss 0.0033\n",
      "epochs 889 train loss 0.0052 valid loss 0.0034\n",
      "epochs 890 train loss 0.0057 valid loss 0.0035\n",
      "epochs 891 train loss 0.0054 valid loss 0.0033\n",
      "epochs 892 train loss 0.0056 valid loss 0.0036\n",
      "epochs 893 train loss 0.0056 valid loss 0.0033\n",
      "epochs 894 train loss 0.0055 valid loss 0.0033\n",
      "epochs 895 train loss 0.0055 valid loss 0.0034\n",
      "epochs 896 train loss 0.0055 valid loss 0.0033\n",
      "epochs 897 train loss 0.0054 valid loss 0.0034\n",
      "epochs 898 train loss 0.0056 valid loss 0.0034\n",
      "epochs 899 train loss 0.0055 valid loss 0.0034\n",
      "epochs 900 train loss 0.0055 valid loss 0.0032\n",
      "record net\n",
      "epochs 901 train loss 0.0053 valid loss 0.0034\n",
      "epochs 902 train loss 0.0052 valid loss 0.0033\n",
      "epochs 903 train loss 0.0054 valid loss 0.0033\n",
      "epochs 904 train loss 0.0056 valid loss 0.0033\n",
      "epochs 905 train loss 0.0053 valid loss 0.0033\n",
      "epochs 906 train loss 0.0053 valid loss 0.0034\n",
      "epochs 907 train loss 0.0056 valid loss 0.0034\n",
      "epochs 908 train loss 0.0053 valid loss 0.0034\n",
      "epochs 909 train loss 0.0053 valid loss 0.0033\n",
      "epochs 910 train loss 0.0054 valid loss 0.0033\n",
      "epochs 911 train loss 0.0056 valid loss 0.0033\n",
      "epochs 912 train loss 0.0055 valid loss 0.0032\n",
      "record net\n",
      "epochs 913 train loss 0.0054 valid loss 0.0033\n",
      "epochs 914 train loss 0.0054 valid loss 0.0033\n",
      "epochs 915 train loss 0.0055 valid loss 0.0033\n",
      "epochs 916 train loss 0.0055 valid loss 0.0033\n",
      "epochs 917 train loss 0.0054 valid loss 0.0032\n",
      "record net\n",
      "epochs 918 train loss 0.0054 valid loss 0.0033\n",
      "epochs 919 train loss 0.0053 valid loss 0.0033\n",
      "epochs 920 train loss 0.0054 valid loss 0.0033\n",
      "epochs 921 train loss 0.0055 valid loss 0.0033\n",
      "epochs 922 train loss 0.0057 valid loss 0.0033\n",
      "epochs 923 train loss 0.0052 valid loss 0.0032\n",
      "epochs 924 train loss 0.0055 valid loss 0.0033\n",
      "epochs 925 train loss 0.0054 valid loss 0.0032\n",
      "epochs 926 train loss 0.0055 valid loss 0.0032\n",
      "epochs 927 train loss 0.0054 valid loss 0.0032\n",
      "epochs 928 train loss 0.0053 valid loss 0.0033\n",
      "epochs 929 train loss 0.0054 valid loss 0.0032\n",
      "epochs 930 train loss 0.0055 valid loss 0.0032\n",
      "epochs 931 train loss 0.0055 valid loss 0.0033\n",
      "epochs 932 train loss 0.0055 valid loss 0.0032\n",
      "record net\n",
      "epochs 933 train loss 0.0053 valid loss 0.0033\n",
      "epochs 934 train loss 0.0053 valid loss 0.0033\n",
      "epochs 935 train loss 0.0052 valid loss 0.0032\n",
      "epochs 936 train loss 0.0053 valid loss 0.0032\n",
      "epochs 937 train loss 0.0055 valid loss 0.0032\n",
      "epochs 938 train loss 0.0054 valid loss 0.0032\n",
      "epochs 939 train loss 0.0056 valid loss 0.0032\n",
      "record net\n",
      "epochs 940 train loss 0.0054 valid loss 0.0033\n",
      "epochs 941 train loss 0.0055 valid loss 0.0033\n",
      "epochs 942 train loss 0.0055 valid loss 0.0033\n",
      "epochs 943 train loss 0.0053 valid loss 0.0032\n",
      "epochs 944 train loss 0.0054 valid loss 0.0033\n",
      "epochs 945 train loss 0.0053 valid loss 0.0033\n",
      "epochs 946 train loss 0.0054 valid loss 0.0031\n",
      "record net\n",
      "epochs 947 train loss 0.0053 valid loss 0.0032\n",
      "epochs 948 train loss 0.0053 valid loss 0.0031\n",
      "record net\n",
      "epochs 949 train loss 0.0054 valid loss 0.0033\n",
      "epochs 950 train loss 0.0052 valid loss 0.0032\n",
      "epochs 951 train loss 0.0053 valid loss 0.0032\n",
      "epochs 952 train loss 0.0053 valid loss 0.0032\n",
      "epochs 953 train loss 0.0054 valid loss 0.0033\n",
      "epochs 954 train loss 0.0054 valid loss 0.0033\n",
      "epochs 955 train loss 0.0054 valid loss 0.0032\n",
      "epochs 956 train loss 0.0052 valid loss 0.0033\n",
      "epochs 957 train loss 0.0053 valid loss 0.0032\n",
      "epochs 958 train loss 0.0053 valid loss 0.0031\n",
      "record net\n",
      "epochs 959 train loss 0.0054 valid loss 0.0032\n",
      "epochs 960 train loss 0.0053 valid loss 0.0031\n",
      "epochs 961 train loss 0.0053 valid loss 0.0032\n",
      "epochs 962 train loss 0.0053 valid loss 0.0033\n",
      "epochs 963 train loss 0.0052 valid loss 0.0032\n",
      "epochs 964 train loss 0.0054 valid loss 0.0031\n",
      "epochs 965 train loss 0.0054 valid loss 0.0032\n",
      "epochs 966 train loss 0.0053 valid loss 0.0032\n",
      "epochs 967 train loss 0.0054 valid loss 0.0031\n",
      "epochs 968 train loss 0.0053 valid loss 0.0032\n",
      "epochs 969 train loss 0.0054 valid loss 0.0032\n",
      "epochs 970 train loss 0.0055 valid loss 0.0031\n",
      "epochs 971 train loss 0.0052 valid loss 0.0031\n",
      "epochs 972 train loss 0.0053 valid loss 0.0031\n",
      "epochs 973 train loss 0.0053 valid loss 0.0031\n",
      "epochs 974 train loss 0.0053 valid loss 0.0033\n",
      "epochs 975 train loss 0.0054 valid loss 0.0031\n",
      "epochs 976 train loss 0.0052 valid loss 0.0031\n",
      "epochs 977 train loss 0.0053 valid loss 0.0032\n",
      "epochs 978 train loss 0.0051 valid loss 0.0031\n",
      "epochs 979 train loss 0.0053 valid loss 0.0032\n",
      "epochs 980 train loss 0.0053 valid loss 0.0032\n",
      "epochs 981 train loss 0.0052 valid loss 0.0032\n",
      "epochs 982 train loss 0.0054 valid loss 0.0032\n",
      "epochs 983 train loss 0.0053 valid loss 0.0031\n",
      "epochs 984 train loss 0.0053 valid loss 0.0032\n",
      "epochs 985 train loss 0.0053 valid loss 0.0033\n",
      "epochs 986 train loss 0.0054 valid loss 0.0031\n",
      "epochs 987 train loss 0.0051 valid loss 0.0031\n",
      "epochs 988 train loss 0.0052 valid loss 0.0030\n",
      "record net\n",
      "epochs 989 train loss 0.0051 valid loss 0.0032\n",
      "epochs 990 train loss 0.0052 valid loss 0.0033\n",
      "epochs 991 train loss 0.0055 valid loss 0.0032\n",
      "epochs 992 train loss 0.0053 valid loss 0.0031\n",
      "epochs 993 train loss 0.0053 valid loss 0.0030\n",
      "record net\n",
      "epochs 994 train loss 0.0054 valid loss 0.0031\n",
      "epochs 995 train loss 0.0052 valid loss 0.0031\n",
      "epochs 996 train loss 0.0053 valid loss 0.0031\n",
      "epochs 997 train loss 0.0053 valid loss 0.0031\n",
      "epochs 998 train loss 0.0052 valid loss 0.0032\n",
      "epochs 999 train loss 0.0054 valid loss 0.0031\n",
      "epochs 1000 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1001 train loss 0.0053 valid loss 0.0033\n",
      "epochs 1002 train loss 0.0053 valid loss 0.0033\n",
      "epochs 1003 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1004 train loss 0.0057 valid loss 0.0031\n",
      "epochs 1005 train loss 0.0053 valid loss 0.0032\n",
      "epochs 1006 train loss 0.0053 valid loss 0.0032\n",
      "epochs 1007 train loss 0.0053 valid loss 0.0032\n",
      "epochs 1008 train loss 0.0054 valid loss 0.0031\n",
      "epochs 1009 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1010 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1011 train loss 0.0052 valid loss 0.0032\n",
      "epochs 1012 train loss 0.0055 valid loss 0.0033\n",
      "epochs 1013 train loss 0.0052 valid loss 0.0032\n",
      "epochs 1014 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1015 train loss 0.0054 valid loss 0.0031\n",
      "epochs 1016 train loss 0.0053 valid loss 0.0033\n",
      "epochs 1017 train loss 0.0054 valid loss 0.0031\n",
      "epochs 1018 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1019 train loss 0.0051 valid loss 0.0032\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1020 train loss 0.0052 valid loss 0.0032\n",
      "epochs 1021 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1022 train loss 0.0051 valid loss 0.0032\n",
      "epochs 1023 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1024 train loss 0.0053 valid loss 0.0032\n",
      "epochs 1025 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1026 train loss 0.0054 valid loss 0.0033\n",
      "epochs 1027 train loss 0.0053 valid loss 0.0032\n",
      "epochs 1028 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1029 train loss 0.0053 valid loss 0.0030\n",
      "record net\n",
      "epochs 1030 train loss 0.0054 valid loss 0.0032\n",
      "epochs 1031 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1032 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1033 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1034 train loss 0.0054 valid loss 0.0030\n",
      "record net\n",
      "epochs 1035 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1036 train loss 0.0050 valid loss 0.0031\n",
      "epochs 1037 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1038 train loss 0.0053 valid loss 0.0030\n",
      "epochs 1039 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1040 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1041 train loss 0.0054 valid loss 0.0030\n",
      "epochs 1042 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1043 train loss 0.0049 valid loss 0.0031\n",
      "epochs 1044 train loss 0.0052 valid loss 0.0030\n",
      "record net\n",
      "epochs 1045 train loss 0.0053 valid loss 0.0030\n",
      "epochs 1046 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1047 train loss 0.0050 valid loss 0.0032\n",
      "epochs 1048 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1049 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1050 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1051 train loss 0.0054 valid loss 0.0031\n",
      "epochs 1052 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1053 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1054 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1055 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1056 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1057 train loss 0.0051 valid loss 0.0032\n",
      "epochs 1058 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1059 train loss 0.0052 valid loss 0.0032\n",
      "epochs 1060 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1061 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1062 train loss 0.0052 valid loss 0.0032\n",
      "epochs 1063 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1064 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1065 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1066 train loss 0.0052 valid loss 0.0029\n",
      "record net\n",
      "epochs 1067 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1068 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1069 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1070 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1071 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1072 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1073 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1074 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1075 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1076 train loss 0.0055 valid loss 0.0031\n",
      "epochs 1077 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1078 train loss 0.0053 valid loss 0.0030\n",
      "epochs 1079 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1080 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1081 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1082 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1083 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1084 train loss 0.0052 valid loss 0.0029\n",
      "record net\n",
      "epochs 1085 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1086 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1087 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1088 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1089 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1090 train loss 0.0049 valid loss 0.0030\n",
      "epochs 1091 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1092 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1093 train loss 0.0053 valid loss 0.0031\n",
      "epochs 1094 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1095 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1096 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1097 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1098 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1099 train loss 0.0053 valid loss 0.0029\n",
      "record net\n",
      "epochs 1100 train loss 0.0050 valid loss 0.0028\n",
      "record net\n",
      "epochs 1101 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1102 train loss 0.0053 valid loss 0.0029\n",
      "epochs 1103 train loss 0.0052 valid loss 0.0028\n",
      "record net\n",
      "epochs 1104 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1105 train loss 0.0052 valid loss 0.0031\n",
      "epochs 1106 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1107 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1108 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1109 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1110 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1111 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1112 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1113 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1114 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1115 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1116 train loss 0.0050 valid loss 0.0032\n",
      "epochs 1117 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1118 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1119 train loss 0.0053 valid loss 0.0030\n",
      "epochs 1120 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1121 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1122 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1123 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1124 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1125 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1126 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1127 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1128 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1129 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1130 train loss 0.0052 valid loss 0.0028\n",
      "epochs 1131 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1132 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1133 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1134 train loss 0.0049 valid loss 0.0030\n",
      "epochs 1135 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1136 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1137 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1138 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1139 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1140 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1141 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1142 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1143 train loss 0.0051 valid loss 0.0031\n",
      "epochs 1144 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1145 train loss 0.0048 valid loss 0.0029\n",
      "epochs 1146 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1147 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1148 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1149 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1150 train loss 0.0052 valid loss 0.0028\n",
      "epochs 1151 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1152 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1153 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1154 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1155 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1156 train loss 0.0051 valid loss 0.0028\n",
      "record net\n",
      "epochs 1157 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1158 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1159 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1160 train loss 0.0052 valid loss 0.0028\n",
      "record net\n",
      "epochs 1161 train loss 0.0049 valid loss 0.0028\n",
      "record net\n",
      "epochs 1162 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1163 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1164 train loss 0.0049 valid loss 0.0030\n",
      "epochs 1165 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1166 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1167 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1168 train loss 0.0051 valid loss 0.0030\n",
      "epochs 1169 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1170 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1171 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1172 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1173 train loss 0.0050 valid loss 0.0028\n",
      "record net\n",
      "epochs 1174 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1175 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1176 train loss 0.0052 valid loss 0.0028\n",
      "epochs 1177 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1178 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1179 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1180 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1181 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1182 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1183 train loss 0.0052 valid loss 0.0030\n",
      "epochs 1184 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1185 train loss 0.0049 valid loss 0.0028\n",
      "record net\n",
      "epochs 1186 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1187 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1188 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1189 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1190 train loss 0.0051 valid loss 0.0028\n",
      "epochs 1191 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1192 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1193 train loss 0.0050 valid loss 0.0028\n",
      "record net\n",
      "epochs 1194 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1195 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1196 train loss 0.0050 valid loss 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1197 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1198 train loss 0.0048 valid loss 0.0027\n",
      "record net\n",
      "epochs 1199 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1200 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1201 train loss 0.0048 valid loss 0.0029\n",
      "epochs 1202 train loss 0.0051 valid loss 0.0028\n",
      "epochs 1203 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1204 train loss 0.0051 valid loss 0.0029\n",
      "epochs 1205 train loss 0.0052 valid loss 0.0028\n",
      "epochs 1206 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1207 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1208 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1209 train loss 0.0050 valid loss 0.0030\n",
      "epochs 1210 train loss 0.0052 valid loss 0.0029\n",
      "epochs 1211 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1212 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1213 train loss 0.0049 valid loss 0.0030\n",
      "epochs 1214 train loss 0.0051 valid loss 0.0028\n",
      "epochs 1215 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1216 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1217 train loss 0.0050 valid loss 0.0027\n",
      "record net\n",
      "epochs 1218 train loss 0.0052 valid loss 0.0027\n",
      "record net\n",
      "epochs 1219 train loss 0.0054 valid loss 0.0027\n",
      "epochs 1220 train loss 0.0052 valid loss 0.0028\n",
      "epochs 1221 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1222 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1223 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1224 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1225 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1226 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1227 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1228 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1229 train loss 0.0047 valid loss 0.0029\n",
      "epochs 1230 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1231 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1232 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1233 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1234 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1235 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1236 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1237 train loss 0.0047 valid loss 0.0029\n",
      "epochs 1238 train loss 0.0049 valid loss 0.0029\n",
      "epochs 1239 train loss 0.0049 valid loss 0.0027\n",
      "record net\n",
      "epochs 1240 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1241 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1242 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1243 train loss 0.0050 valid loss 0.0029\n",
      "epochs 1244 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1245 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1246 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1247 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1248 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1249 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1250 train loss 0.0047 valid loss 0.0028\n",
      "epochs 1251 train loss 0.0049 valid loss 0.0030\n",
      "epochs 1252 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1253 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1254 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1255 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1256 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1257 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1258 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1259 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1260 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1261 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1262 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1263 train loss 0.0051 valid loss 0.0027\n",
      "epochs 1264 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1265 train loss 0.0051 valid loss 0.0028\n",
      "epochs 1266 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1267 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1268 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1269 train loss 0.0051 valid loss 0.0027\n",
      "epochs 1270 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1271 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1272 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1273 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1274 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1275 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1276 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1277 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1278 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1279 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1280 train loss 0.0048 valid loss 0.0027\n",
      "record net\n",
      "epochs 1281 train loss 0.0048 valid loss 0.0026\n",
      "record net\n",
      "epochs 1282 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1283 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1284 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1285 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1286 train loss 0.0049 valid loss 0.0028\n",
      "epochs 1287 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1288 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1289 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1290 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1291 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1292 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1293 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1294 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1295 train loss 0.0051 valid loss 0.0028\n",
      "epochs 1296 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1297 train loss 0.0051 valid loss 0.0026\n",
      "epochs 1298 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1299 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1300 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1301 train loss 0.0050 valid loss 0.0028\n",
      "epochs 1302 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1303 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1304 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1305 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1306 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1307 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1308 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1309 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1310 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1311 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1312 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1313 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1314 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1315 train loss 0.0048 valid loss 0.0026\n",
      "record net\n",
      "epochs 1316 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1317 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1318 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1319 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1320 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1321 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1322 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1323 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1324 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1325 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1326 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1327 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1328 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1329 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1330 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1331 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1332 train loss 0.0049 valid loss 0.0026\n",
      "record net\n",
      "epochs 1333 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1334 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1335 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1336 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1337 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1338 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1339 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1340 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1341 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1342 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1343 train loss 0.0051 valid loss 0.0027\n",
      "epochs 1344 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1345 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1346 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1347 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1348 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1349 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1350 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1351 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1352 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1353 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1354 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1355 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1356 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1357 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1358 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1359 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1360 train loss 0.0049 valid loss 0.0025\n",
      "record net\n",
      "epochs 1361 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1362 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1363 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1364 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1365 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1366 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1367 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1368 train loss 0.0048 valid loss 0.0025\n",
      "record net\n",
      "epochs 1369 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1370 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1371 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1372 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1373 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1374 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1375 train loss 0.0048 valid loss 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1376 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1377 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1378 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1379 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1380 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1381 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1382 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1383 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1384 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1385 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1386 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1387 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1388 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1389 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1390 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1391 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1392 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1393 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1394 train loss 0.0045 valid loss 0.0027\n",
      "epochs 1395 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1396 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1397 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1398 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1399 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1400 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1401 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1402 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1403 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1404 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1405 train loss 0.0049 valid loss 0.0027\n",
      "epochs 1406 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1407 train loss 0.0048 valid loss 0.0025\n",
      "record net\n",
      "epochs 1408 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1409 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1410 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1411 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1412 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1413 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1414 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1415 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1416 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1417 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1418 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1419 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1420 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1421 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1422 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1423 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1424 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1425 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1426 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1427 train loss 0.0050 valid loss 0.0026\n",
      "epochs 1428 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1429 train loss 0.0048 valid loss 0.0028\n",
      "epochs 1430 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1431 train loss 0.0050 valid loss 0.0025\n",
      "epochs 1432 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1433 train loss 0.0045 valid loss 0.0025\n",
      "record net\n",
      "epochs 1434 train loss 0.0047 valid loss 0.0025\n",
      "record net\n",
      "epochs 1435 train loss 0.0047 valid loss 0.0027\n",
      "epochs 1436 train loss 0.0048 valid loss 0.0025\n",
      "record net\n",
      "epochs 1437 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1438 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1439 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1440 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1441 train loss 0.0048 valid loss 0.0026\n",
      "epochs 1442 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1443 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1444 train loss 0.0047 valid loss 0.0024\n",
      "record net\n",
      "epochs 1445 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1446 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1447 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1448 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1449 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1450 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1451 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1452 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1453 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1454 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1455 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1456 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1457 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1458 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1459 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1460 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1461 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1462 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1463 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1464 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1465 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1466 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1467 train loss 0.0046 valid loss 0.0027\n",
      "epochs 1468 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1469 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1470 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1471 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1472 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1473 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1474 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1475 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1476 train loss 0.0047 valid loss 0.0024\n",
      "record net\n",
      "epochs 1477 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1478 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1479 train loss 0.0050 valid loss 0.0027\n",
      "epochs 1480 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1481 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1482 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1483 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1484 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1485 train loss 0.0045 valid loss 0.0027\n",
      "epochs 1486 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1487 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1488 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1489 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1490 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1491 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1492 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1493 train loss 0.0053 valid loss 0.0026\n",
      "epochs 1494 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1495 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1496 train loss 0.0049 valid loss 0.0026\n",
      "epochs 1497 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1498 train loss 0.0044 valid loss 0.0026\n",
      "epochs 1499 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1500 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1501 train loss 0.0043 valid loss 0.0025\n",
      "epochs 1502 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1503 train loss 0.0049 valid loss 0.0024\n",
      "epochs 1504 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1505 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1506 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1507 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1508 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1509 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1510 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1511 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1512 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1513 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1514 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1515 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1516 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1517 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1518 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1519 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1520 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1521 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1522 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1523 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1524 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1525 train loss 0.0048 valid loss 0.0027\n",
      "epochs 1526 train loss 0.0045 valid loss 0.0026\n",
      "epochs 1527 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1528 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1529 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1530 train loss 0.0047 valid loss 0.0026\n",
      "epochs 1531 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1532 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1533 train loss 0.0046 valid loss 0.0023\n",
      "record net\n",
      "epochs 1534 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1535 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1536 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1537 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1538 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1539 train loss 0.0048 valid loss 0.0025\n",
      "epochs 1540 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1541 train loss 0.0045 valid loss 0.0023\n",
      "record net\n",
      "epochs 1542 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1543 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1544 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1545 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1546 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1547 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1548 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1549 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1550 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1551 train loss 0.0045 valid loss 0.0025\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1552 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1553 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1554 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1555 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1556 train loss 0.0045 valid loss 0.0023\n",
      "record net\n",
      "epochs 1557 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1558 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1559 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1560 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1561 train loss 0.0050 valid loss 0.0023\n",
      "epochs 1562 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1563 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1564 train loss 0.0047 valid loss 0.0023\n",
      "record net\n",
      "epochs 1565 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1566 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1567 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1568 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1569 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1570 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1571 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1572 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1573 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1574 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1575 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1576 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1577 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1578 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1579 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1580 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1581 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1582 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1583 train loss 0.0046 valid loss 0.0025\n",
      "epochs 1584 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1585 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1586 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1587 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1588 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1589 train loss 0.0044 valid loss 0.0025\n",
      "epochs 1590 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1591 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1592 train loss 0.0049 valid loss 0.0024\n",
      "epochs 1593 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1594 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1595 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1596 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1597 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1598 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1599 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1600 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1601 train loss 0.0049 valid loss 0.0025\n",
      "epochs 1602 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1603 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1604 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1605 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1606 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1607 train loss 0.0047 valid loss 0.0023\n",
      "record net\n",
      "epochs 1608 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1609 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1610 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1611 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1612 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1613 train loss 0.0048 valid loss 0.0023\n",
      "record net\n",
      "epochs 1614 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1615 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1616 train loss 0.0049 valid loss 0.0024\n",
      "epochs 1617 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1618 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1619 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1620 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1621 train loss 0.0045 valid loss 0.0023\n",
      "record net\n",
      "epochs 1622 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1623 train loss 0.0042 valid loss 0.0024\n",
      "epochs 1624 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1625 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1626 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1627 train loss 0.0046 valid loss 0.0026\n",
      "epochs 1628 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1629 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1630 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1631 train loss 0.0044 valid loss 0.0025\n",
      "epochs 1632 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1633 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1634 train loss 0.0047 valid loss 0.0025\n",
      "epochs 1635 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1636 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1637 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1638 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1639 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1640 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1641 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1642 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1643 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1644 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1645 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1646 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1647 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1648 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1649 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1650 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1651 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1652 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1653 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1654 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1655 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1656 train loss 0.0045 valid loss 0.0023\n",
      "record net\n",
      "epochs 1657 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1658 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1659 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1660 train loss 0.0047 valid loss 0.0022\n",
      "record net\n",
      "epochs 1661 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1662 train loss 0.0048 valid loss 0.0023\n",
      "epochs 1663 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1664 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1665 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1666 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1667 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1668 train loss 0.0048 valid loss 0.0023\n",
      "epochs 1669 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1670 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1671 train loss 0.0045 valid loss 0.0022\n",
      "record net\n",
      "epochs 1672 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1673 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1674 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1675 train loss 0.0048 valid loss 0.0023\n",
      "epochs 1676 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1677 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1678 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1679 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1680 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1681 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1682 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1683 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1684 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1685 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1686 train loss 0.0044 valid loss 0.0022\n",
      "record net\n",
      "epochs 1687 train loss 0.0045 valid loss 0.0022\n",
      "record net\n",
      "epochs 1688 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1689 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1690 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1691 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1692 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1693 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1694 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1695 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1696 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1697 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1698 train loss 0.0048 valid loss 0.0023\n",
      "epochs 1699 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1700 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1701 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1702 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1703 train loss 0.0043 valid loss 0.0024\n",
      "epochs 1704 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1705 train loss 0.0045 valid loss 0.0025\n",
      "epochs 1706 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1707 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1708 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1709 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1710 train loss 0.0043 valid loss 0.0024\n",
      "epochs 1711 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1712 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1713 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1714 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1715 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1716 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1717 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1718 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1719 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1720 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1721 train loss 0.0046 valid loss 0.0024\n",
      "epochs 1722 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1723 train loss 0.0047 valid loss 0.0024\n",
      "epochs 1724 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1725 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1726 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1727 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1728 train loss 0.0048 valid loss 0.0024\n",
      "epochs 1729 train loss 0.0048 valid loss 0.0024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1730 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1731 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1732 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1733 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1734 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1735 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1736 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1737 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1738 train loss 0.0047 valid loss 0.0023\n",
      "epochs 1739 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1740 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1741 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1742 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1743 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1744 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1745 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1746 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1747 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1748 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1749 train loss 0.0044 valid loss 0.0021\n",
      "record net\n",
      "epochs 1750 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1751 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1752 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1753 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1754 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1755 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1756 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1757 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1758 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1759 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1760 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1761 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1762 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1763 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1764 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1765 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1766 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1767 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1768 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1769 train loss 0.0047 valid loss 0.0022\n",
      "epochs 1770 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1771 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1772 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1773 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1774 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1775 train loss 0.0047 valid loss 0.0022\n",
      "epochs 1776 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1777 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1778 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1779 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1780 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1781 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1782 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1783 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1784 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1785 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1786 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1787 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1788 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1789 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1790 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1791 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1792 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1793 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1794 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1795 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1796 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1797 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1798 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1799 train loss 0.0044 valid loss 0.0021\n",
      "record net\n",
      "epochs 1800 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1801 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1802 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1803 train loss 0.0047 valid loss 0.0022\n",
      "epochs 1804 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1805 train loss 0.0046 valid loss 0.0023\n",
      "epochs 1806 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1807 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1808 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1809 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1810 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1811 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1812 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1813 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1814 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1815 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1816 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1817 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1818 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1819 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1820 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1821 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1822 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1823 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1824 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1825 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1826 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1827 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1828 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1829 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1830 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1831 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1832 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1833 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1834 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1835 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1836 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1837 train loss 0.0047 valid loss 0.0022\n",
      "epochs 1838 train loss 0.0042 valid loss 0.0023\n",
      "epochs 1839 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1840 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1841 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1842 train loss 0.0042 valid loss 0.0021\n",
      "record net\n",
      "epochs 1843 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1844 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1845 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1846 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1847 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1848 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1849 train loss 0.0047 valid loss 0.0022\n",
      "epochs 1850 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1851 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1852 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1853 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1854 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1855 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1856 train loss 0.0041 valid loss 0.0022\n",
      "epochs 1857 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1858 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1859 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1860 train loss 0.0047 valid loss 0.0021\n",
      "epochs 1861 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1862 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1863 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1864 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1865 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1866 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1867 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1868 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1869 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1870 train loss 0.0047 valid loss 0.0021\n",
      "record net\n",
      "epochs 1871 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1872 train loss 0.0042 valid loss 0.0023\n",
      "epochs 1873 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1874 train loss 0.0044 valid loss 0.0024\n",
      "epochs 1875 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1876 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1877 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1878 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1879 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1880 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1881 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1882 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1883 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1884 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1885 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1886 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1887 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1888 train loss 0.0042 valid loss 0.0020\n",
      "record net\n",
      "epochs 1889 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1890 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1891 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1892 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1893 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1894 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1895 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1896 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1897 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1898 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1899 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1900 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1901 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1902 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1903 train loss 0.0043 valid loss 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epochs 1904 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1905 train loss 0.0046 valid loss 0.0021\n",
      "epochs 1906 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1907 train loss 0.0042 valid loss 0.0023\n",
      "epochs 1908 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1909 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1910 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1911 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1912 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1913 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1914 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1915 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1916 train loss 0.0042 valid loss 0.0021\n",
      "epochs 1917 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1918 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1919 train loss 0.0046 valid loss 0.0021\n",
      "epochs 1920 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1921 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1922 train loss 0.0043 valid loss 0.0023\n",
      "epochs 1923 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1924 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1925 train loss 0.0045 valid loss 0.0024\n",
      "epochs 1926 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1927 train loss 0.0046 valid loss 0.0021\n",
      "epochs 1928 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1929 train loss 0.0046 valid loss 0.0022\n",
      "epochs 1930 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1931 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1932 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1933 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1934 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1935 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1936 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1937 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1938 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1939 train loss 0.0045 valid loss 0.0023\n",
      "epochs 1940 train loss 0.0044 valid loss 0.0023\n",
      "epochs 1941 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1942 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1943 train loss 0.0042 valid loss 0.0023\n",
      "epochs 1944 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1945 train loss 0.0042 valid loss 0.0021\n",
      "epochs 1946 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1947 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1948 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1949 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1950 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1951 train loss 0.0042 valid loss 0.0021\n",
      "epochs 1952 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1953 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1954 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1955 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1956 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1957 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1958 train loss 0.0045 valid loss 0.0022\n",
      "epochs 1959 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1960 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1961 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1962 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1963 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1964 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1965 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1966 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1967 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1968 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1969 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1970 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1971 train loss 0.0041 valid loss 0.0021\n",
      "epochs 1972 train loss 0.0044 valid loss 0.0020\n",
      "record net\n",
      "epochs 1973 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1974 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1975 train loss 0.0041 valid loss 0.0021\n",
      "epochs 1976 train loss 0.0044 valid loss 0.0021\n",
      "epochs 1977 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1978 train loss 0.0043 valid loss 0.0020\n",
      "record net\n",
      "epochs 1979 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1980 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1981 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1982 train loss 0.0043 valid loss 0.0020\n",
      "epochs 1983 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1984 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1985 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1986 train loss 0.0043 valid loss 0.0020\n",
      "epochs 1987 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1988 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1989 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1990 train loss 0.0044 valid loss 0.0020\n",
      "epochs 1991 train loss 0.0045 valid loss 0.0020\n",
      "epochs 1992 train loss 0.0042 valid loss 0.0022\n",
      "epochs 1993 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1994 train loss 0.0045 valid loss 0.0021\n",
      "epochs 1995 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1996 train loss 0.0043 valid loss 0.0022\n",
      "epochs 1997 train loss 0.0043 valid loss 0.0021\n",
      "epochs 1998 train loss 0.0044 valid loss 0.0022\n",
      "epochs 1999 train loss 0.0043 valid loss 0.0021\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "net = train(net,train_iter,train_iter,loss_function,optimizer,num_epochs=2000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# make prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product    Hydrogen</th>\n",
       "      <th>Product    Methane</th>\n",
       "      <th>Product    Ethane</th>\n",
       "      <th>Product    Propane</th>\n",
       "      <th>Product    n-Butane</th>\n",
       "      <th>Product    i-Butane</th>\n",
       "      <th>Product    C4 Naphthenes</th>\n",
       "      <th>Product    n-Pentane</th>\n",
       "      <th>Product    C5 i-Paraffins</th>\n",
       "      <th>Product    C5 Naphthenes</th>\n",
       "      <th>...</th>\n",
       "      <th>Product    M-Xylene</th>\n",
       "      <th>Product    O-Xylene</th>\n",
       "      <th>Product    n-Nonane</th>\n",
       "      <th>Product    C9 i-Paraffins</th>\n",
       "      <th>Product    C9 Naphthenes</th>\n",
       "      <th>Product    C9 Aromtics</th>\n",
       "      <th>Product    C10+ n-Paraffins</th>\n",
       "      <th>Product    C10+ i-Paraffins</th>\n",
       "      <th>Product    C10+ Naphthenes</th>\n",
       "      <th>Product    C10+ Aromtics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2570.281738</td>\n",
       "      <td>809.604370</td>\n",
       "      <td>2248.246582</td>\n",
       "      <td>2829.455078</td>\n",
       "      <td>1121.593384</td>\n",
       "      <td>1066.235229</td>\n",
       "      <td>1.078425</td>\n",
       "      <td>1700.134766</td>\n",
       "      <td>2575.158447</td>\n",
       "      <td>37.027390</td>\n",
       "      <td>...</td>\n",
       "      <td>10113.442383</td>\n",
       "      <td>5292.500488</td>\n",
       "      <td>7.691960</td>\n",
       "      <td>25.572769</td>\n",
       "      <td>20.527189</td>\n",
       "      <td>9392.476562</td>\n",
       "      <td>92.661507</td>\n",
       "      <td>189.635086</td>\n",
       "      <td>127.380112</td>\n",
       "      <td>1821.751099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2568.565674</td>\n",
       "      <td>821.107666</td>\n",
       "      <td>2247.023926</td>\n",
       "      <td>2765.768555</td>\n",
       "      <td>1139.721558</td>\n",
       "      <td>1092.523071</td>\n",
       "      <td>1.097369</td>\n",
       "      <td>1689.393921</td>\n",
       "      <td>2561.115479</td>\n",
       "      <td>36.098186</td>\n",
       "      <td>...</td>\n",
       "      <td>10142.819336</td>\n",
       "      <td>5288.895020</td>\n",
       "      <td>8.074911</td>\n",
       "      <td>27.269241</td>\n",
       "      <td>20.588343</td>\n",
       "      <td>9438.040039</td>\n",
       "      <td>93.772896</td>\n",
       "      <td>193.177002</td>\n",
       "      <td>129.202393</td>\n",
       "      <td>1832.818604</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2583.992188</td>\n",
       "      <td>781.575012</td>\n",
       "      <td>2209.318359</td>\n",
       "      <td>2860.459961</td>\n",
       "      <td>1093.054565</td>\n",
       "      <td>1026.217529</td>\n",
       "      <td>1.066441</td>\n",
       "      <td>1683.907837</td>\n",
       "      <td>2548.185547</td>\n",
       "      <td>36.855713</td>\n",
       "      <td>...</td>\n",
       "      <td>10266.083008</td>\n",
       "      <td>5334.181152</td>\n",
       "      <td>6.848237</td>\n",
       "      <td>23.516626</td>\n",
       "      <td>18.868420</td>\n",
       "      <td>9239.918945</td>\n",
       "      <td>93.676979</td>\n",
       "      <td>189.831573</td>\n",
       "      <td>127.418968</td>\n",
       "      <td>1765.874268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2573.735596</td>\n",
       "      <td>820.358887</td>\n",
       "      <td>2231.850830</td>\n",
       "      <td>2780.442383</td>\n",
       "      <td>1123.729736</td>\n",
       "      <td>1063.630737</td>\n",
       "      <td>1.074602</td>\n",
       "      <td>1687.425781</td>\n",
       "      <td>2559.392578</td>\n",
       "      <td>35.795753</td>\n",
       "      <td>...</td>\n",
       "      <td>10130.073242</td>\n",
       "      <td>5295.624023</td>\n",
       "      <td>8.339573</td>\n",
       "      <td>28.512247</td>\n",
       "      <td>20.648420</td>\n",
       "      <td>9475.931641</td>\n",
       "      <td>92.818619</td>\n",
       "      <td>191.377853</td>\n",
       "      <td>127.996727</td>\n",
       "      <td>1840.438354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2577.452393</td>\n",
       "      <td>822.569885</td>\n",
       "      <td>2244.199463</td>\n",
       "      <td>2824.304199</td>\n",
       "      <td>1082.654175</td>\n",
       "      <td>1012.689209</td>\n",
       "      <td>1.069610</td>\n",
       "      <td>1699.019897</td>\n",
       "      <td>2577.608154</td>\n",
       "      <td>34.358597</td>\n",
       "      <td>...</td>\n",
       "      <td>10171.770508</td>\n",
       "      <td>5287.781250</td>\n",
       "      <td>8.353992</td>\n",
       "      <td>28.906725</td>\n",
       "      <td>19.677374</td>\n",
       "      <td>9553.414062</td>\n",
       "      <td>90.154129</td>\n",
       "      <td>184.376968</td>\n",
       "      <td>123.488640</td>\n",
       "      <td>1850.180298</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product    Hydrogen  Product    Methane  Product    Ethane  \\\n",
       "0          2570.281738          809.604370        2248.246582   \n",
       "1          2568.565674          821.107666        2247.023926   \n",
       "2          2583.992188          781.575012        2209.318359   \n",
       "3          2573.735596          820.358887        2231.850830   \n",
       "4          2577.452393          822.569885        2244.199463   \n",
       "\n",
       "   Product    Propane  Product    n-Butane  Product    i-Butane  \\\n",
       "0         2829.455078          1121.593384          1066.235229   \n",
       "1         2765.768555          1139.721558          1092.523071   \n",
       "2         2860.459961          1093.054565          1026.217529   \n",
       "3         2780.442383          1123.729736          1063.630737   \n",
       "4         2824.304199          1082.654175          1012.689209   \n",
       "\n",
       "   Product    C4 Naphthenes  Product    n-Pentane  Product    C5 i-Paraffins  \\\n",
       "0                  1.078425           1700.134766                2575.158447   \n",
       "1                  1.097369           1689.393921                2561.115479   \n",
       "2                  1.066441           1683.907837                2548.185547   \n",
       "3                  1.074602           1687.425781                2559.392578   \n",
       "4                  1.069610           1699.019897                2577.608154   \n",
       "\n",
       "   Product    C5 Naphthenes  ...  Product    M-Xylene  Product    O-Xylene  \\\n",
       "0                 37.027390  ...         10113.442383          5292.500488   \n",
       "1                 36.098186  ...         10142.819336          5288.895020   \n",
       "2                 36.855713  ...         10266.083008          5334.181152   \n",
       "3                 35.795753  ...         10130.073242          5295.624023   \n",
       "4                 34.358597  ...         10171.770508          5287.781250   \n",
       "\n",
       "   Product    n-Nonane  Product    C9 i-Paraffins  Product    C9 Naphthenes  \\\n",
       "0             7.691960                  25.572769                 20.527189   \n",
       "1             8.074911                  27.269241                 20.588343   \n",
       "2             6.848237                  23.516626                 18.868420   \n",
       "3             8.339573                  28.512247                 20.648420   \n",
       "4             8.353992                  28.906725                 19.677374   \n",
       "\n",
       "   Product    C9 Aromtics  Product    C10+ n-Paraffins  \\\n",
       "0             9392.476562                    92.661507   \n",
       "1             9438.040039                    93.772896   \n",
       "2             9239.918945                    93.676979   \n",
       "3             9475.931641                    92.818619   \n",
       "4             9553.414062                    90.154129   \n",
       "\n",
       "   Product    C10+ i-Paraffins  Product    C10+ Naphthenes  \\\n",
       "0                   189.635086                  127.380112   \n",
       "1                   193.177002                  129.202393   \n",
       "2                   189.831573                  127.418968   \n",
       "3                   191.377853                  127.996727   \n",
       "4                   184.376968                  123.488640   \n",
       "\n",
       "   Product    C10+ Aromtics  \n",
       "0               1821.751099  \n",
       "1               1832.818604  \n",
       "2               1765.874268  \n",
       "3               1840.438354  \n",
       "4               1850.180298  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = net(X_test).cpu().detach().numpy()\n",
    "y_pred = mm_y.inverse_transform(y_pred)\n",
    "y_pred = pd.DataFrame(y_pred,columns=y_col)\n",
    "y_pred.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product    Hydrogen</th>\n",
       "      <th>Product    Methane</th>\n",
       "      <th>Product    Ethane</th>\n",
       "      <th>Product    Propane</th>\n",
       "      <th>Product    n-Butane</th>\n",
       "      <th>Product    i-Butane</th>\n",
       "      <th>Product    C4 Naphthenes</th>\n",
       "      <th>Product    n-Pentane</th>\n",
       "      <th>Product    C5 i-Paraffins</th>\n",
       "      <th>Product    C5 Naphthenes</th>\n",
       "      <th>...</th>\n",
       "      <th>Product    M-Xylene</th>\n",
       "      <th>Product    O-Xylene</th>\n",
       "      <th>Product    n-Nonane</th>\n",
       "      <th>Product    C9 i-Paraffins</th>\n",
       "      <th>Product    C9 Naphthenes</th>\n",
       "      <th>Product    C9 Aromtics</th>\n",
       "      <th>Product    C10+ n-Paraffins</th>\n",
       "      <th>Product    C10+ i-Paraffins</th>\n",
       "      <th>Product    C10+ Naphthenes</th>\n",
       "      <th>Product    C10+ Aromtics</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2585.543945</td>\n",
       "      <td>783.050415</td>\n",
       "      <td>2167.787842</td>\n",
       "      <td>2652.459229</td>\n",
       "      <td>1190.827881</td>\n",
       "      <td>1204.990967</td>\n",
       "      <td>0.993305</td>\n",
       "      <td>1659.135864</td>\n",
       "      <td>2504.534424</td>\n",
       "      <td>37.759483</td>\n",
       "      <td>...</td>\n",
       "      <td>10368.238281</td>\n",
       "      <td>5203.674805</td>\n",
       "      <td>7.924977</td>\n",
       "      <td>28.818098</td>\n",
       "      <td>21.613575</td>\n",
       "      <td>9198.000977</td>\n",
       "      <td>89.397423</td>\n",
       "      <td>174.555038</td>\n",
       "      <td>119.134483</td>\n",
       "      <td>1788.525391</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2603.471924</td>\n",
       "      <td>802.383057</td>\n",
       "      <td>2194.137207</td>\n",
       "      <td>2121.544189</td>\n",
       "      <td>1468.593384</td>\n",
       "      <td>1563.974609</td>\n",
       "      <td>0.991749</td>\n",
       "      <td>1688.823730</td>\n",
       "      <td>2555.859619</td>\n",
       "      <td>37.822845</td>\n",
       "      <td>...</td>\n",
       "      <td>10326.885742</td>\n",
       "      <td>5182.920898</td>\n",
       "      <td>8.026574</td>\n",
       "      <td>27.728163</td>\n",
       "      <td>21.890656</td>\n",
       "      <td>9217.683594</td>\n",
       "      <td>88.513573</td>\n",
       "      <td>172.790543</td>\n",
       "      <td>118.854881</td>\n",
       "      <td>1775.654785</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2583.133789</td>\n",
       "      <td>875.061646</td>\n",
       "      <td>2180.788086</td>\n",
       "      <td>2890.277100</td>\n",
       "      <td>1133.260010</td>\n",
       "      <td>1070.766968</td>\n",
       "      <td>1.117023</td>\n",
       "      <td>1658.076660</td>\n",
       "      <td>2512.558350</td>\n",
       "      <td>37.748615</td>\n",
       "      <td>...</td>\n",
       "      <td>10314.416992</td>\n",
       "      <td>5176.662598</td>\n",
       "      <td>7.963961</td>\n",
       "      <td>27.511864</td>\n",
       "      <td>20.995895</td>\n",
       "      <td>9191.858398</td>\n",
       "      <td>94.822845</td>\n",
       "      <td>185.389496</td>\n",
       "      <td>127.154457</td>\n",
       "      <td>1778.275024</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2569.629395</td>\n",
       "      <td>888.716736</td>\n",
       "      <td>2207.623291</td>\n",
       "      <td>2813.154541</td>\n",
       "      <td>1111.260864</td>\n",
       "      <td>1039.724121</td>\n",
       "      <td>0.992776</td>\n",
       "      <td>1702.433350</td>\n",
       "      <td>2574.746338</td>\n",
       "      <td>39.185349</td>\n",
       "      <td>...</td>\n",
       "      <td>10330.272461</td>\n",
       "      <td>5184.620117</td>\n",
       "      <td>7.294888</td>\n",
       "      <td>25.532106</td>\n",
       "      <td>21.155176</td>\n",
       "      <td>9204.890625</td>\n",
       "      <td>87.612442</td>\n",
       "      <td>169.090637</td>\n",
       "      <td>118.264397</td>\n",
       "      <td>1773.150635</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2565.668457</td>\n",
       "      <td>887.869019</td>\n",
       "      <td>2179.576416</td>\n",
       "      <td>2809.469482</td>\n",
       "      <td>1067.980591</td>\n",
       "      <td>977.900513</td>\n",
       "      <td>1.119704</td>\n",
       "      <td>1716.807129</td>\n",
       "      <td>2595.738525</td>\n",
       "      <td>39.400585</td>\n",
       "      <td>...</td>\n",
       "      <td>10360.566406</td>\n",
       "      <td>5199.824219</td>\n",
       "      <td>7.954566</td>\n",
       "      <td>28.925694</td>\n",
       "      <td>20.971128</td>\n",
       "      <td>9265.553711</td>\n",
       "      <td>88.705460</td>\n",
       "      <td>173.766342</td>\n",
       "      <td>119.839462</td>\n",
       "      <td>1788.048950</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 33 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Product    Hydrogen  Product    Methane  Product    Ethane  \\\n",
       "0          2585.543945          783.050415        2167.787842   \n",
       "1          2603.471924          802.383057        2194.137207   \n",
       "2          2583.133789          875.061646        2180.788086   \n",
       "3          2569.629395          888.716736        2207.623291   \n",
       "4          2565.668457          887.869019        2179.576416   \n",
       "\n",
       "   Product    Propane  Product    n-Butane  Product    i-Butane  \\\n",
       "0         2652.459229          1190.827881          1204.990967   \n",
       "1         2121.544189          1468.593384          1563.974609   \n",
       "2         2890.277100          1133.260010          1070.766968   \n",
       "3         2813.154541          1111.260864          1039.724121   \n",
       "4         2809.469482          1067.980591           977.900513   \n",
       "\n",
       "   Product    C4 Naphthenes  Product    n-Pentane  Product    C5 i-Paraffins  \\\n",
       "0                  0.993305           1659.135864                2504.534424   \n",
       "1                  0.991749           1688.823730                2555.859619   \n",
       "2                  1.117023           1658.076660                2512.558350   \n",
       "3                  0.992776           1702.433350                2574.746338   \n",
       "4                  1.119704           1716.807129                2595.738525   \n",
       "\n",
       "   Product    C5 Naphthenes  ...  Product    M-Xylene  Product    O-Xylene  \\\n",
       "0                 37.759483  ...         10368.238281          5203.674805   \n",
       "1                 37.822845  ...         10326.885742          5182.920898   \n",
       "2                 37.748615  ...         10314.416992          5176.662598   \n",
       "3                 39.185349  ...         10330.272461          5184.620117   \n",
       "4                 39.400585  ...         10360.566406          5199.824219   \n",
       "\n",
       "   Product    n-Nonane  Product    C9 i-Paraffins  Product    C9 Naphthenes  \\\n",
       "0             7.924977                  28.818098                 21.613575   \n",
       "1             8.026574                  27.728163                 21.890656   \n",
       "2             7.963961                  27.511864                 20.995895   \n",
       "3             7.294888                  25.532106                 21.155176   \n",
       "4             7.954566                  28.925694                 20.971128   \n",
       "\n",
       "   Product    C9 Aromtics  Product    C10+ n-Paraffins  \\\n",
       "0             9198.000977                    89.397423   \n",
       "1             9217.683594                    88.513573   \n",
       "2             9191.858398                    94.822845   \n",
       "3             9204.890625                    87.612442   \n",
       "4             9265.553711                    88.705460   \n",
       "\n",
       "   Product    C10+ i-Paraffins  Product    C10+ Naphthenes  \\\n",
       "0                   174.555038                  119.134483   \n",
       "1                   172.790543                  118.854881   \n",
       "2                   185.389496                  127.154457   \n",
       "3                   169.090637                  118.264397   \n",
       "4                   173.766342                  119.839462   \n",
       "\n",
       "   Product    C10+ Aromtics  \n",
       "0               1788.525391  \n",
       "1               1775.654785  \n",
       "2               1778.275024  \n",
       "3               1773.150635  \n",
       "4               1788.048950  \n",
       "\n",
       "[5 rows x 33 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_real = y_test.cpu().detach().numpy()\n",
    "y_real = mm_y.inverse_transform(y_real)\n",
    "y_real = pd.DataFrame(y_real,columns=y_col)\n",
    "y_real.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score,mean_squared_error\n",
    "def mape(y_true, y_pred): \n",
    "    y_true, y_pred = np.array(y_true), np.array(y_pred)\n",
    "    return np.mean(np.abs((y_true - y_pred) / y_true)) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>R2</th>\n",
       "      <th>MSE</th>\n",
       "      <th>MAPE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Product    Hydrogen</th>\n",
       "      <td>0.447548</td>\n",
       "      <td>1777.54</td>\n",
       "      <td>1.30384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Methane</th>\n",
       "      <td>-0.265042</td>\n",
       "      <td>12383.2</td>\n",
       "      <td>10.089</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Ethane</th>\n",
       "      <td>0.599523</td>\n",
       "      <td>6433.45</td>\n",
       "      <td>3.00227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Propane</th>\n",
       "      <td>-0.180578</td>\n",
       "      <td>95718</td>\n",
       "      <td>10.0183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Butane</th>\n",
       "      <td>-0.688841</td>\n",
       "      <td>25876.2</td>\n",
       "      <td>9.93737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    i-Butane</th>\n",
       "      <td>-0.525037</td>\n",
       "      <td>47324.6</td>\n",
       "      <td>13.0915</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C4 Naphthenes</th>\n",
       "      <td>0.0237147</td>\n",
       "      <td>0.685482</td>\n",
       "      <td>9.12679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Pentane</th>\n",
       "      <td>0.641317</td>\n",
       "      <td>15771.2</td>\n",
       "      <td>4.85433</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C5 i-Paraffins</th>\n",
       "      <td>0.640511</td>\n",
       "      <td>33924.3</td>\n",
       "      <td>4.76066</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C5 Naphthenes</th>\n",
       "      <td>-2.1067</td>\n",
       "      <td>6.92808</td>\n",
       "      <td>5.85004</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Hexane</th>\n",
       "      <td>0.262686</td>\n",
       "      <td>669.754</td>\n",
       "      <td>3.75718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C6 i-Paraffins</th>\n",
       "      <td>-0.174738</td>\n",
       "      <td>4674.53</td>\n",
       "      <td>4.02041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C6 Naphthenes</th>\n",
       "      <td>0.150372</td>\n",
       "      <td>301.331</td>\n",
       "      <td>11.9277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Benzene</th>\n",
       "      <td>-0.0500767</td>\n",
       "      <td>10186.4</td>\n",
       "      <td>4.42713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Heptane</th>\n",
       "      <td>0.152729</td>\n",
       "      <td>8146.6</td>\n",
       "      <td>7.98902</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C7 i-Paraffins</th>\n",
       "      <td>0.186427</td>\n",
       "      <td>84515</td>\n",
       "      <td>6.94246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C7 Naphthenes</th>\n",
       "      <td>0.265828</td>\n",
       "      <td>1724.2</td>\n",
       "      <td>10.5264</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Toluene</th>\n",
       "      <td>0.612742</td>\n",
       "      <td>579388</td>\n",
       "      <td>3.96591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Octane</th>\n",
       "      <td>0.125807</td>\n",
       "      <td>1716.61</td>\n",
       "      <td>23.4367</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C8 i-Paraffins</th>\n",
       "      <td>0.147449</td>\n",
       "      <td>15975.8</td>\n",
       "      <td>18.2449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C8 Naphthenes</th>\n",
       "      <td>0.0793021</td>\n",
       "      <td>1274.08</td>\n",
       "      <td>21.3192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    Ethylbenzene</th>\n",
       "      <td>-0.419289</td>\n",
       "      <td>17334.5</td>\n",
       "      <td>3.71663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    P-Xylene</th>\n",
       "      <td>-21.02</td>\n",
       "      <td>191010</td>\n",
       "      <td>14.7294</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    M-Xylene</th>\n",
       "      <td>0.414454</td>\n",
       "      <td>62976.4</td>\n",
       "      <td>2.26663</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    O-Xylene</th>\n",
       "      <td>0.276971</td>\n",
       "      <td>19587.7</td>\n",
       "      <td>2.62332</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    n-Nonane</th>\n",
       "      <td>0.161288</td>\n",
       "      <td>19.1483</td>\n",
       "      <td>24.4325</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C9 i-Paraffins</th>\n",
       "      <td>0.122527</td>\n",
       "      <td>498.829</td>\n",
       "      <td>33.3152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C9 Naphthenes</th>\n",
       "      <td>-0.552594</td>\n",
       "      <td>5.69518</td>\n",
       "      <td>7.5863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C9 Aromtics</th>\n",
       "      <td>0.752856</td>\n",
       "      <td>109266</td>\n",
       "      <td>2.93842</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C10+ n-Paraffins</th>\n",
       "      <td>-0.264499</td>\n",
       "      <td>289.324</td>\n",
       "      <td>9.93716</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C10+ i-Paraffins</th>\n",
       "      <td>-0.0719003</td>\n",
       "      <td>898.785</td>\n",
       "      <td>10.8488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C10+ Naphthenes</th>\n",
       "      <td>-0.0816996</td>\n",
       "      <td>462.268</td>\n",
       "      <td>10.2062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Product    C10+ Aromtics</th>\n",
       "      <td>0.493751</td>\n",
       "      <td>21804.4</td>\n",
       "      <td>5.66168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>AVG</th>\n",
       "      <td>-0.601309</td>\n",
       "      <td>41574</td>\n",
       "      <td>9.60161</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    R2       MSE     MAPE\n",
       "Product    Hydrogen           0.447548   1777.54  1.30384\n",
       "Product    Methane           -0.265042   12383.2   10.089\n",
       "Product    Ethane             0.599523   6433.45  3.00227\n",
       "Product    Propane           -0.180578     95718  10.0183\n",
       "Product    n-Butane          -0.688841   25876.2  9.93737\n",
       "Product    i-Butane          -0.525037   47324.6  13.0915\n",
       "Product    C4 Naphthenes     0.0237147  0.685482  9.12679\n",
       "Product    n-Pentane          0.641317   15771.2  4.85433\n",
       "Product    C5 i-Paraffins     0.640511   33924.3  4.76066\n",
       "Product    C5 Naphthenes       -2.1067   6.92808  5.85004\n",
       "Product    n-Hexane           0.262686   669.754  3.75718\n",
       "Product    C6 i-Paraffins    -0.174738   4674.53  4.02041\n",
       "Product    C6 Naphthenes      0.150372   301.331  11.9277\n",
       "Product    Benzene          -0.0500767   10186.4  4.42713\n",
       "Product    n-Heptane          0.152729    8146.6  7.98902\n",
       "Product    C7 i-Paraffins     0.186427     84515  6.94246\n",
       "Product    C7 Naphthenes      0.265828    1724.2  10.5264\n",
       "Product    Toluene            0.612742    579388  3.96591\n",
       "Product    n-Octane           0.125807   1716.61  23.4367\n",
       "Product    C8 i-Paraffins     0.147449   15975.8  18.2449\n",
       "Product    C8 Naphthenes     0.0793021   1274.08  21.3192\n",
       "Product    Ethylbenzene      -0.419289   17334.5  3.71663\n",
       "Product    P-Xylene             -21.02    191010  14.7294\n",
       "Product    M-Xylene           0.414454   62976.4  2.26663\n",
       "Product    O-Xylene           0.276971   19587.7  2.62332\n",
       "Product    n-Nonane           0.161288   19.1483  24.4325\n",
       "Product    C9 i-Paraffins     0.122527   498.829  33.3152\n",
       "Product    C9 Naphthenes     -0.552594   5.69518   7.5863\n",
       "Product    C9 Aromtics        0.752856    109266  2.93842\n",
       "Product    C10+ n-Paraffins  -0.264499   289.324  9.93716\n",
       "Product    C10+ i-Paraffins -0.0719003   898.785  10.8488\n",
       "Product    C10+ Naphthenes  -0.0816996   462.268  10.2062\n",
       "Product    C10+ Aromtics      0.493751   21804.4  5.66168\n",
       "AVG                          -0.601309     41574  9.60161"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res = pd.DataFrame(index=y_col,columns=['R2','MSE','MAPE'])\n",
    "\n",
    "for i in y_col:\n",
    "    res.loc[i,'R2'] = r2_score(y_real[i],y_pred[i])\n",
    "    res.loc[i,'MSE'] = mean_squared_error(y_real[i],y_pred[i])\n",
    "    res.loc[i,'MAPE'] = mape(y_real[i],y_pred[i])\n",
    "res.loc['AVG'] = res.mean(axis=0)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
